{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4e8431b-5b14-4ce0-8d52-8eece073a588",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_EPOCHS = 500\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 0.001\n",
    "SMILES_COL = 'Column3'\n",
    "WAVELENGTH_COL = 'Column5'\n",
    "URL = '/home/ishii/graduation_research/data/csvファイル/dft_B3LYP_6-31G*_zinc_for-sale_1000000_0to100000.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca771bf3-36b2-4fec-836d-266ac0d51e60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#変更後のデータセット\n",
    "import torch\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, url, smiles_col, wavelength_col):\n",
    "        self.max_length = 0\n",
    "        self.dummy_char = '_'\n",
    "        \n",
    "        self.url = url\n",
    "        self.smiles_col = smiles_col\n",
    "        self.smiles = []\n",
    "        self.words = self.load_words()\n",
    "        self.uniq_words = self.get_uniq_words()\n",
    "        self.index_to_word = {index: word for index, word in enumerate(self.uniq_words)}\n",
    "        self.word_to_index = {word: index for index, word in enumerate(self.uniq_words)}\n",
    "        self.words_indexes = [self.word_to_index[w] for w in self.words]\n",
    "\n",
    "        self.wavelength_col = wavelength_col\n",
    "        self.wavelengths = []\n",
    "        self.items = self.generate_items()\n",
    "        \n",
    "        self.dummmy_index = self.word_to_index[self.dummy_char]\n",
    "\n",
    "    def load_words(self):\n",
    "        train_df = pd.read_csv(self.url, usecols=[SMILES_COL])\n",
    "        self.smiles = list(train_df[self.smiles_col])\n",
    "        for i, smile in enumerate(self.smiles):\n",
    "            new_smile = smile[1:]\n",
    "            self.smiles[i] = new_smile\n",
    "        self.max_length = max(len(smile) for smile in self.smiles)\n",
    "        self.smiles = list(smile.ljust(self.max_length, self.dummy_char) for smile in self.smiles)\n",
    "        train_df = pd.Series(self.smiles)\n",
    "        text = train_df.str.cat(sep=' ')\n",
    "        text = \"\".join(text.split(' '))\n",
    "        return [text[i] for i in range(len(text))]\n",
    "    \n",
    "    def generate_items(self):\n",
    "        train_df = pd.read_csv(self.url, usecols=[WAVELENGTH_COL])\n",
    "        self.wavelengths = list(train_df[self.wavelength_col])\n",
    "        items = []\n",
    "        for i, smile in enumerate(self.smiles):\n",
    "            smile = list(smile)\n",
    "            items.append([self.word_to_index[w] for w in smile])\n",
    "        return items\n",
    "\n",
    "    def get_uniq_words(self):\n",
    "        word_counts = Counter(self.words)\n",
    "        return sorted(word_counts, key=word_counts.get, reverse=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.wavelengths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (\n",
    "            torch.tensor(self.items[index]),\n",
    "            torch.tensor(self.wavelengths[index])\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "281d2fdc-f4d5-4996-a3c7-0a2a265c21a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(url=URL, smiles_col=SMILES_COL, wavelength_col=WAVELENGTH_COL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0267ec8-658a-4e5c-8b58-ba5a20136c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([ 6,  1,  5,  1,  1,  1,  3,  2, 20,  4,  1,  1,  5,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0]), tensor(248.7000))\n"
     ]
    }
   ],
   "source": [
    "print(dataset[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd788f74-7bb4-4c23-ab60-18fb3f15af08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87628\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c80b1a8d-0167-41db-b0d3-c46072e6e02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff953cc2-a21b-4620-b448-7d5395224691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 6,  1,  5,  1,  1,  1,  1,  3,  6,  4,  1,  5,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 6,  1,  5,  1,  1,  1,  3,  2, 20,  4,  1,  1,  5,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0]])\n",
      "tensor([239.7600, 248.7000])\n",
      "tensor([[ 2,  8,  2,  3,  2, 23,  9,  4,  2,  3,  8,  6,  4,  6,  2,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 2,  1,  5,  1, 10,  1,  3,  2,  4,  1, 10,  5,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0]])\n",
      "tensor([277.4000, 305.1800])\n",
      "tensor([[ 2,  1,  5, 10,  1,  1, 10,  1,  5,  2,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 9,  2,  1,  5,  1,  1,  1, 10,  1,  5,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0]])\n",
      "tensor([303.8400, 261.6700])\n",
      "tensor([[ 2,  1,  5,  1,  1,  3,  6,  4,  1,  1,  1,  5,  2, 20,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 2,  6,  1,  5,  1,  1,  1,  3,  6,  4,  1,  1,  5,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0]])\n",
      "tensor([251.6400, 259.0300])\n",
      "tensor([[ 6,  8,  2,  3,  6,  4,  1,  5,  1,  1,  1, 10,  1,  5,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 6,  8,  2,  3,  6,  4,  1,  5,  1,  1,  1,  1,  1,  5,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0]])\n",
      "tensor([287.6800, 263.9900])\n",
      "tensor([[ 9,  2,  2,  1,  5,  1,  1, 11, 10, 15, 12, 10,  5,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 9,  8,  2,  3,  6,  4,  1,  5,  1, 10,  1,  1, 10,  5,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0]])\n",
      "tensor([197.7500, 318.5700])\n",
      "tensor([[ 2,  2,  5,  3,  2,  4,  2,  6,  2,  3,  9,  4,  8,  9,  5,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 9,  1,  5, 10,  1, 10,  1,  7, 11, 10, 15, 12,  1, 10,  1,  5,  7,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0]])\n",
      "tensor([180.6400, 247.2000])\n",
      "tensor([[ 2,  6,  2,  3,  8,  6,  4,  1,  5,  1,  1,  1, 10,  1,  5,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 6,  8,  2,  3,  6,  4,  1,  5,  1,  1,  1, 11, 10, 24, 12,  3, 11,  6,\n",
      "         17, 12,  4,  1,  5,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0]])\n",
      "tensor([287.5600, 333.9000])\n",
      "tensor([[ 2,  1,  5,  1,  1,  3,  6,  4,  1,  1,  3,  2,  4,  1,  5,  2, 20,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 6,  8,  1,  5, 22,  1,  7,  1,  1,  3,  6,  4,  1,  1,  1,  7, 21,  5,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0]])\n",
      "tensor([247.8200, 259.8100])\n",
      "tensor([[ 6,  2,  1,  5,  1,  1,  1, 10,  1,  5,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 2,  1,  5,  1,  1,  3,  2,  4,  1,  3,  8,  6,  4, 11, 10, 15, 12, 10,\n",
      "          5,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0]])\n",
      "tensor([255.6200, 306.8800])\n",
      "tensor([[ 6,  1,  5, 10, 21,  1,  7,  1,  1,  3,  2, 20,  4,  1,  1,  1,  5,  7,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 9,  1,  5,  1,  1,  1,  1,  1,  5,  9,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0]])\n",
      "tensor([294.3600, 254.5300])\n"
     ]
    }
   ],
   "source": [
    "for batch, (x, y) in enumerate(dataloader):\n",
    "    print(x)\n",
    "    print(y)\n",
    "    if batch == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "963eec5a-0677-478b-8f00-91974d4e7ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#変更後のモデル\n",
    "import torch\n",
    "\n",
    "class bid_LSTM_Predictor(torch.nn.Module):\n",
    "    def __init__(self, dataset):\n",
    "        super(bid_LSTM_Predictor, self).__init__()\n",
    "        self.lstm_size = 128\n",
    "        self.embedding_dim = 128\n",
    "        self.num_layers = 3\n",
    "\n",
    "        n_vocab = len(dataset.uniq_words)\n",
    "        self.embedding = torch.nn.Embedding(\n",
    "            num_embeddings=n_vocab,\n",
    "            embedding_dim=self.embedding_dim,\n",
    "            padding_idx=dataset.dummmy_index\n",
    "        )\n",
    "        self.lstm = torch.nn.LSTM(\n",
    "            input_size=self.lstm_size,\n",
    "            hidden_size=self.lstm_size,\n",
    "            num_layers=self.num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=0.2,\n",
    "            bidirectional = True\n",
    "        )\n",
    "        self.fc = torch.nn.Linear(2 * self.lstm_size, 1)\n",
    "\n",
    "    def forward(self, x, prev_state):\n",
    "        embed = self.embedding(x)\n",
    "        output, state = self.lstm(embed, prev_state)\n",
    "        logits = self.fc(output)\n",
    "\n",
    "        return logits, state\n",
    "\n",
    "    def init_state(self, batch_size):\n",
    "        return (torch.zeros(2 * self.num_layers, batch_size, self.lstm_size),\n",
    "                torch.zeros(2 * self.num_layers, batch_size, self.lstm_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2cfd0211-c662-47bc-a69c-f76ddb5031c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#変更後の訓練プロセス\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def train(dataset, train_dataset, model):\n",
    "    losses = []\n",
    "    val_losses = []\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, drop_last=True)\n",
    "\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    \n",
    "    #scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2)\n",
    "\n",
    "    for epoch in range(MAX_EPOCHS):\n",
    "        model.train()\n",
    "        \n",
    "        state_h, state_c = model.init_state(BATCH_SIZE)\n",
    "        state_h = state_h.to(device)\n",
    "        state_c = state_c.to(device)\n",
    "        total_loss = 0\n",
    "        total_val_loss = 0\n",
    "\n",
    "        for batch, (x, y) in enumerate(train_dataloader):\n",
    "            if batch < int(len(train_dataloader) * 0.75):\n",
    "                model.train()\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                y_pred, (state_h, state_c) = model(x.to(device), (state_h, state_c))\n",
    "                y_pred_permute = torch.permute(y_pred, (2, 1, 0))\n",
    "                loss = criterion(y_pred_permute[0, dataset.max_length-1], y.to(device))\n",
    "                total_loss += loss.item()\n",
    "\n",
    "                state_h = state_h.detach()\n",
    "                state_c = state_c.detach()\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "            else:\n",
    "                model.eval()\n",
    "                \n",
    "                y_pred, (state_h, state_c) = model(x.to(device), (state_h, state_c))\n",
    "                y_pred_permute = torch.permute(y_pred, (2, 1, 0))\n",
    "                val_loss = criterion(y_pred_permute[0, dataset.max_length-1], y.to(device))\n",
    "                total_val_loss += val_loss.item()    \n",
    "                \n",
    "                state_h = state_h.detach()\n",
    "                state_c = state_c.detach()\n",
    "        \n",
    "        average_total_train_loss = total_loss / int(len(train_dataloader) * 0.75)\n",
    "        average_total_val_loss = total_val_loss / (len(train_dataloader) - int(len(train_dataloader) * 0.75))\n",
    "        \n",
    "        print(\"Epoch: {}, train_Loss: {:.3f}, val_Loss: {:.3f}\".format(\n",
    "            epoch+1, \n",
    "            average_total_train_loss,\n",
    "            average_total_val_loss\n",
    "        ))\n",
    "        losses.append(average_total_train_loss)\n",
    "        val_losses.append(average_total_val_loss)\n",
    "    return losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a67f788d-627e-42a1-89e3-38510896c476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"device: \" + str(device) + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b912c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(url=URL, smiles_col=SMILES_COL, wavelength_col=WAVELENGTH_COL)\n",
    "n_samples = len(dataset)\n",
    "indices = list(range(n_samples))\n",
    "train_size = int(n_samples * 0.8)\n",
    "test_size = n_samples - train_size\n",
    "\n",
    "train_dataset = torch.utils.data.Subset(dataset, indices[:train_size])\n",
    "test_dataset = torch.utils.data.Subset(dataset, indices[train_size:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e7f1ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70102\n",
      "17526\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset))\n",
    "print(len(test_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d15e87d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "410\n",
      "137\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, drop_last=True)\n",
    "print(int(len(train_dataloader) * 0.75))\n",
    "print(len(train_dataloader) - int(len(train_dataloader) * 0.75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b9ca541-5e56-4e0f-a42b-5c1b0ec0c701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, train_Loss: 69135.055, val_Loss: 44143.488\n",
      "Epoch: 2, train_Loss: 31250.820, val_Loss: 18476.860\n",
      "Epoch: 3, train_Loss: 13167.324, val_Loss: 7322.306\n",
      "Epoch: 4, train_Loss: 5945.250, val_Loss: 3583.789\n",
      "Epoch: 5, train_Loss: 3764.724, val_Loss: 2741.643\n",
      "Epoch: 6, train_Loss: 3318.857, val_Loss: 2655.185\n",
      "Epoch: 7, train_Loss: 3273.220, val_Loss: 2669.969\n",
      "Epoch: 8, train_Loss: 3275.741, val_Loss: 2678.365\n",
      "Epoch: 9, train_Loss: 3277.035, val_Loss: 2681.729\n",
      "Epoch: 10, train_Loss: 3276.538, val_Loss: 2683.508\n",
      "Epoch: 11, train_Loss: 3275.195, val_Loss: 2684.184\n",
      "Epoch: 12, train_Loss: 3273.189, val_Loss: 2683.623\n",
      "Epoch: 13, train_Loss: 3270.583, val_Loss: 2681.893\n",
      "Epoch: 14, train_Loss: 3267.555, val_Loss: 2679.355\n",
      "Epoch: 15, train_Loss: 3264.368, val_Loss: 2676.501\n",
      "Epoch: 16, train_Loss: 3261.299, val_Loss: 2673.764\n",
      "Epoch: 17, train_Loss: 3258.553, val_Loss: 2671.400\n",
      "Epoch: 18, train_Loss: 3256.243, val_Loss: 2669.498\n",
      "Epoch: 19, train_Loss: 3254.390, val_Loss: 2668.040\n",
      "Epoch: 20, train_Loss: 3252.958, val_Loss: 2666.957\n",
      "Epoch: 21, train_Loss: 3251.880, val_Loss: 2666.169\n",
      "Epoch: 22, train_Loss: 3251.086, val_Loss: 2665.604\n",
      "Epoch: 23, train_Loss: 3250.510, val_Loss: 2665.203\n",
      "Epoch: 24, train_Loss: 3250.097, val_Loss: 2664.919\n",
      "Epoch: 25, train_Loss: 3249.803, val_Loss: 2664.719\n",
      "Epoch: 26, train_Loss: 3249.595, val_Loss: 2664.579\n",
      "Epoch: 27, train_Loss: 3249.448, val_Loss: 2664.481\n",
      "Epoch: 28, train_Loss: 3249.345, val_Loss: 2664.412\n",
      "Epoch: 29, train_Loss: 3249.272, val_Loss: 2664.364\n",
      "Epoch: 30, train_Loss: 3249.222, val_Loss: 2664.330\n",
      "Epoch: 31, train_Loss: 3249.186, val_Loss: 2664.307\n",
      "Epoch: 32, train_Loss: 3249.161, val_Loss: 2664.290\n",
      "Epoch: 33, train_Loss: 3249.144, val_Loss: 2664.279\n",
      "Epoch: 34, train_Loss: 3249.131, val_Loss: 2664.270\n",
      "Epoch: 35, train_Loss: 3249.123, val_Loss: 2664.265\n",
      "Epoch: 36, train_Loss: 3249.117, val_Loss: 2664.261\n",
      "Epoch: 37, train_Loss: 3249.112, val_Loss: 2664.258\n",
      "Epoch: 38, train_Loss: 3249.109, val_Loss: 2664.257\n",
      "Epoch: 39, train_Loss: 3249.107, val_Loss: 2664.255\n",
      "Epoch: 40, train_Loss: 3249.105, val_Loss: 2664.254\n",
      "Epoch: 41, train_Loss: 3249.104, val_Loss: 2664.254\n",
      "Epoch: 42, train_Loss: 3249.103, val_Loss: 2664.253\n",
      "Epoch: 43, train_Loss: 3249.103, val_Loss: 2664.253\n",
      "Epoch: 44, train_Loss: 3249.102, val_Loss: 2664.253\n",
      "Epoch: 45, train_Loss: 3249.102, val_Loss: 2664.252\n",
      "Epoch: 46, train_Loss: 3249.101, val_Loss: 2664.252\n",
      "Epoch: 47, train_Loss: 3249.101, val_Loss: 2664.252\n",
      "Epoch: 48, train_Loss: 3249.101, val_Loss: 2664.252\n",
      "Epoch: 49, train_Loss: 3249.100, val_Loss: 2664.252\n",
      "Epoch: 50, train_Loss: 3249.100, val_Loss: 2664.252\n",
      "Epoch: 51, train_Loss: 3249.100, val_Loss: 2664.252\n",
      "Epoch: 52, train_Loss: 3249.100, val_Loss: 2664.252\n",
      "Epoch: 53, train_Loss: 3249.099, val_Loss: 2664.252\n",
      "Epoch: 54, train_Loss: 3249.099, val_Loss: 2664.252\n",
      "Epoch: 55, train_Loss: 3249.039, val_Loss: 2658.468\n",
      "Epoch: 56, train_Loss: 3247.813, val_Loss: 2659.889\n",
      "Epoch: 57, train_Loss: 3249.868, val_Loss: 2665.632\n",
      "Epoch: 58, train_Loss: 3253.315, val_Loss: 2655.786\n",
      "Epoch: 59, train_Loss: 3251.339, val_Loss: 2666.603\n",
      "Epoch: 60, train_Loss: 3240.309, val_Loss: 2667.661\n",
      "Epoch: 61, train_Loss: 3297.069, val_Loss: 2669.060\n",
      "Epoch: 62, train_Loss: 3289.377, val_Loss: 2670.537\n",
      "Epoch: 63, train_Loss: 3258.178, val_Loss: 2670.431\n",
      "Epoch: 64, train_Loss: 3258.582, val_Loss: 2670.470\n",
      "Epoch: 65, train_Loss: 3247.138, val_Loss: 2670.520\n",
      "Epoch: 66, train_Loss: 3250.569, val_Loss: 2671.702\n",
      "Epoch: 67, train_Loss: 3254.430, val_Loss: 2673.296\n",
      "Epoch: 68, train_Loss: 3253.689, val_Loss: 2673.868\n",
      "Epoch: 69, train_Loss: 3250.673, val_Loss: 2672.835\n",
      "Epoch: 70, train_Loss: 3227.742, val_Loss: 2632.088\n",
      "Epoch: 71, train_Loss: 3202.382, val_Loss: 2615.909\n",
      "Epoch: 72, train_Loss: 3169.405, val_Loss: 2635.932\n",
      "Epoch: 73, train_Loss: 3190.390, val_Loss: 2620.643\n",
      "Epoch: 74, train_Loss: 3164.869, val_Loss: 2591.080\n",
      "Epoch: 75, train_Loss: 3132.883, val_Loss: 2608.902\n",
      "Epoch: 76, train_Loss: 3149.982, val_Loss: 2590.511\n",
      "Epoch: 77, train_Loss: 3126.303, val_Loss: 2587.695\n",
      "Epoch: 78, train_Loss: 2967.926, val_Loss: 1942.585\n",
      "Epoch: 79, train_Loss: 2100.878, val_Loss: 1465.300\n",
      "Epoch: 80, train_Loss: 1678.233, val_Loss: 1215.760\n",
      "Epoch: 81, train_Loss: 1449.465, val_Loss: 1061.226\n",
      "Epoch: 82, train_Loss: 1299.011, val_Loss: 1001.736\n",
      "Epoch: 83, train_Loss: 1194.713, val_Loss: 959.370\n",
      "Epoch: 84, train_Loss: 1112.965, val_Loss: 904.881\n",
      "Epoch: 85, train_Loss: 1044.966, val_Loss: 908.532\n",
      "Epoch: 86, train_Loss: 1007.895, val_Loss: 869.442\n",
      "Epoch: 87, train_Loss: 951.429, val_Loss: 817.583\n",
      "Epoch: 88, train_Loss: 905.733, val_Loss: 776.849\n",
      "Epoch: 89, train_Loss: 865.487, val_Loss: 773.937\n",
      "Epoch: 90, train_Loss: 829.120, val_Loss: 740.805\n",
      "Epoch: 91, train_Loss: 791.218, val_Loss: 766.432\n",
      "Epoch: 92, train_Loss: 770.981, val_Loss: 726.116\n",
      "Epoch: 93, train_Loss: 741.357, val_Loss: 714.032\n",
      "Epoch: 94, train_Loss: 708.945, val_Loss: 703.711\n",
      "Epoch: 95, train_Loss: 675.693, val_Loss: 693.182\n",
      "Epoch: 96, train_Loss: 652.801, val_Loss: 729.300\n",
      "Epoch: 97, train_Loss: 635.583, val_Loss: 699.114\n",
      "Epoch: 98, train_Loss: 609.575, val_Loss: 686.503\n",
      "Epoch: 99, train_Loss: 593.031, val_Loss: 715.879\n",
      "Epoch: 100, train_Loss: 561.407, val_Loss: 664.540\n",
      "Epoch: 101, train_Loss: 546.942, val_Loss: 651.903\n",
      "Epoch: 102, train_Loss: 543.728, val_Loss: 674.019\n",
      "Epoch: 103, train_Loss: 518.961, val_Loss: 647.528\n",
      "Epoch: 104, train_Loss: 493.827, val_Loss: 660.561\n",
      "Epoch: 105, train_Loss: 489.952, val_Loss: 658.488\n",
      "Epoch: 106, train_Loss: 478.976, val_Loss: 641.119\n",
      "Epoch: 107, train_Loss: 468.484, val_Loss: 676.716\n",
      "Epoch: 108, train_Loss: 450.267, val_Loss: 662.569\n",
      "Epoch: 109, train_Loss: 442.224, val_Loss: 633.920\n",
      "Epoch: 110, train_Loss: 425.284, val_Loss: 639.932\n",
      "Epoch: 111, train_Loss: 416.074, val_Loss: 638.695\n",
      "Epoch: 112, train_Loss: 434.719, val_Loss: 637.995\n",
      "Epoch: 113, train_Loss: 406.080, val_Loss: 654.401\n",
      "Epoch: 114, train_Loss: 391.242, val_Loss: 624.741\n",
      "Epoch: 115, train_Loss: 384.607, val_Loss: 614.761\n",
      "Epoch: 116, train_Loss: 375.396, val_Loss: 629.654\n",
      "Epoch: 117, train_Loss: 371.216, val_Loss: 632.076\n",
      "Epoch: 118, train_Loss: 376.940, val_Loss: 593.350\n",
      "Epoch: 119, train_Loss: 353.244, val_Loss: 612.136\n",
      "Epoch: 120, train_Loss: 350.887, val_Loss: 620.387\n",
      "Epoch: 121, train_Loss: 349.639, val_Loss: 613.640\n",
      "Epoch: 122, train_Loss: 372.663, val_Loss: 619.505\n",
      "Epoch: 123, train_Loss: 333.406, val_Loss: 615.991\n",
      "Epoch: 124, train_Loss: 324.149, val_Loss: 614.888\n",
      "Epoch: 125, train_Loss: 320.484, val_Loss: 612.257\n",
      "Epoch: 126, train_Loss: 305.961, val_Loss: 624.159\n",
      "Epoch: 127, train_Loss: 307.496, val_Loss: 598.180\n",
      "Epoch: 128, train_Loss: 304.634, val_Loss: 605.368\n",
      "Epoch: 129, train_Loss: 307.304, val_Loss: 626.441\n",
      "Epoch: 130, train_Loss: 309.682, val_Loss: 610.257\n",
      "Epoch: 131, train_Loss: 299.165, val_Loss: 599.731\n",
      "Epoch: 132, train_Loss: 280.796, val_Loss: 612.464\n",
      "Epoch: 133, train_Loss: 279.935, val_Loss: 597.490\n",
      "Epoch: 134, train_Loss: 279.534, val_Loss: 605.945\n",
      "Epoch: 135, train_Loss: 270.034, val_Loss: 593.526\n",
      "Epoch: 136, train_Loss: 268.233, val_Loss: 625.604\n",
      "Epoch: 137, train_Loss: 259.927, val_Loss: 617.283\n",
      "Epoch: 138, train_Loss: 266.289, val_Loss: 603.983\n",
      "Epoch: 139, train_Loss: 270.577, val_Loss: 596.247\n",
      "Epoch: 140, train_Loss: 259.700, val_Loss: 615.186\n",
      "Epoch: 141, train_Loss: 259.338, val_Loss: 601.572\n",
      "Epoch: 142, train_Loss: 262.294, val_Loss: 609.504\n",
      "Epoch: 143, train_Loss: 245.526, val_Loss: 595.040\n",
      "Epoch: 144, train_Loss: 249.364, val_Loss: 580.638\n",
      "Epoch: 145, train_Loss: 248.116, val_Loss: 592.785\n",
      "Epoch: 146, train_Loss: 243.043, val_Loss: 619.750\n",
      "Epoch: 147, train_Loss: 239.912, val_Loss: 587.115\n",
      "Epoch: 148, train_Loss: 236.168, val_Loss: 594.166\n",
      "Epoch: 149, train_Loss: 234.221, val_Loss: 572.029\n",
      "Epoch: 150, train_Loss: 225.466, val_Loss: 586.691\n",
      "Epoch: 151, train_Loss: 229.404, val_Loss: 593.501\n",
      "Epoch: 152, train_Loss: 229.890, val_Loss: 604.905\n",
      "Epoch: 153, train_Loss: 223.470, val_Loss: 586.921\n",
      "Epoch: 154, train_Loss: 227.178, val_Loss: 583.290\n",
      "Epoch: 155, train_Loss: 237.153, val_Loss: 595.873\n",
      "Epoch: 156, train_Loss: 224.106, val_Loss: 588.920\n",
      "Epoch: 157, train_Loss: 219.470, val_Loss: 603.257\n",
      "Epoch: 158, train_Loss: 211.717, val_Loss: 603.603\n",
      "Epoch: 159, train_Loss: 211.231, val_Loss: 615.439\n",
      "Epoch: 160, train_Loss: 210.462, val_Loss: 587.276\n",
      "Epoch: 161, train_Loss: 205.395, val_Loss: 597.797\n",
      "Epoch: 162, train_Loss: 204.337, val_Loss: 601.780\n",
      "Epoch: 163, train_Loss: 198.722, val_Loss: 599.204\n",
      "Epoch: 164, train_Loss: 201.391, val_Loss: 601.939\n",
      "Epoch: 165, train_Loss: 212.405, val_Loss: 613.781\n",
      "Epoch: 166, train_Loss: 200.044, val_Loss: 593.676\n",
      "Epoch: 167, train_Loss: 189.491, val_Loss: 585.621\n",
      "Epoch: 168, train_Loss: 192.175, val_Loss: 602.023\n",
      "Epoch: 169, train_Loss: 198.799, val_Loss: 590.701\n",
      "Epoch: 170, train_Loss: 200.189, val_Loss: 592.878\n",
      "Epoch: 171, train_Loss: 187.904, val_Loss: 593.717\n",
      "Epoch: 172, train_Loss: 187.316, val_Loss: 573.402\n",
      "Epoch: 173, train_Loss: 237.725, val_Loss: 603.934\n",
      "Epoch: 174, train_Loss: 211.340, val_Loss: 585.563\n",
      "Epoch: 175, train_Loss: 191.796, val_Loss: 598.511\n",
      "Epoch: 176, train_Loss: 181.126, val_Loss: 581.378\n",
      "Epoch: 177, train_Loss: 177.401, val_Loss: 577.413\n",
      "Epoch: 178, train_Loss: 175.245, val_Loss: 587.704\n",
      "Epoch: 179, train_Loss: 171.926, val_Loss: 580.935\n",
      "Epoch: 180, train_Loss: 171.221, val_Loss: 580.143\n",
      "Epoch: 181, train_Loss: 173.807, val_Loss: 581.485\n",
      "Epoch: 182, train_Loss: 175.017, val_Loss: 568.398\n",
      "Epoch: 183, train_Loss: 172.319, val_Loss: 588.773\n",
      "Epoch: 184, train_Loss: 167.407, val_Loss: 580.568\n",
      "Epoch: 185, train_Loss: 192.335, val_Loss: 592.190\n",
      "Epoch: 186, train_Loss: 178.022, val_Loss: 591.458\n",
      "Epoch: 187, train_Loss: 171.556, val_Loss: 571.198\n",
      "Epoch: 188, train_Loss: 167.631, val_Loss: 585.250\n",
      "Epoch: 189, train_Loss: 170.670, val_Loss: 594.983\n",
      "Epoch: 190, train_Loss: 166.337, val_Loss: 567.837\n",
      "Epoch: 191, train_Loss: 163.244, val_Loss: 583.267\n",
      "Epoch: 192, train_Loss: 157.415, val_Loss: 588.365\n",
      "Epoch: 193, train_Loss: 159.470, val_Loss: 571.169\n",
      "Epoch: 194, train_Loss: 156.683, val_Loss: 575.348\n",
      "Epoch: 195, train_Loss: 155.012, val_Loss: 592.716\n",
      "Epoch: 196, train_Loss: 155.164, val_Loss: 576.608\n",
      "Epoch: 197, train_Loss: 162.223, val_Loss: 592.870\n",
      "Epoch: 198, train_Loss: 161.953, val_Loss: 588.301\n",
      "Epoch: 199, train_Loss: 158.186, val_Loss: 586.121\n",
      "Epoch: 200, train_Loss: 150.553, val_Loss: 582.422\n",
      "Epoch: 201, train_Loss: 153.011, val_Loss: 575.447\n",
      "Epoch: 202, train_Loss: 159.772, val_Loss: 569.273\n",
      "Epoch: 203, train_Loss: 149.601, val_Loss: 572.918\n",
      "Epoch: 204, train_Loss: 147.583, val_Loss: 578.322\n",
      "Epoch: 205, train_Loss: 145.654, val_Loss: 579.133\n",
      "Epoch: 206, train_Loss: 142.607, val_Loss: 576.783\n",
      "Epoch: 207, train_Loss: 144.487, val_Loss: 584.028\n",
      "Epoch: 208, train_Loss: 146.144, val_Loss: 588.654\n",
      "Epoch: 209, train_Loss: 142.715, val_Loss: 577.626\n",
      "Epoch: 210, train_Loss: 144.304, val_Loss: 577.046\n",
      "Epoch: 211, train_Loss: 146.487, val_Loss: 575.667\n",
      "Epoch: 212, train_Loss: 144.344, val_Loss: 578.623\n",
      "Epoch: 213, train_Loss: 145.196, val_Loss: 583.615\n",
      "Epoch: 214, train_Loss: 142.183, val_Loss: 584.688\n",
      "Epoch: 215, train_Loss: 146.238, val_Loss: 591.302\n",
      "Epoch: 216, train_Loss: 142.476, val_Loss: 574.361\n",
      "Epoch: 217, train_Loss: 140.447, val_Loss: 578.432\n",
      "Epoch: 218, train_Loss: 144.996, val_Loss: 577.500\n",
      "Epoch: 219, train_Loss: 142.632, val_Loss: 572.478\n",
      "Epoch: 220, train_Loss: 144.373, val_Loss: 565.286\n",
      "Epoch: 221, train_Loss: 135.810, val_Loss: 578.152\n",
      "Epoch: 222, train_Loss: 132.233, val_Loss: 572.573\n",
      "Epoch: 223, train_Loss: 132.531, val_Loss: 565.379\n",
      "Epoch: 224, train_Loss: 141.091, val_Loss: 573.431\n",
      "Epoch: 225, train_Loss: 146.403, val_Loss: 584.095\n",
      "Epoch: 226, train_Loss: 135.170, val_Loss: 567.800\n",
      "Epoch: 227, train_Loss: 135.053, val_Loss: 574.144\n",
      "Epoch: 228, train_Loss: 128.202, val_Loss: 577.800\n",
      "Epoch: 229, train_Loss: 126.145, val_Loss: 569.718\n",
      "Epoch: 230, train_Loss: 125.290, val_Loss: 571.572\n",
      "Epoch: 231, train_Loss: 126.254, val_Loss: 582.669\n",
      "Epoch: 232, train_Loss: 131.718, val_Loss: 581.711\n",
      "Epoch: 233, train_Loss: 130.588, val_Loss: 579.866\n",
      "Epoch: 234, train_Loss: 145.978, val_Loss: 575.064\n",
      "Epoch: 235, train_Loss: 131.515, val_Loss: 569.210\n",
      "Epoch: 236, train_Loss: 126.197, val_Loss: 574.544\n",
      "Epoch: 237, train_Loss: 124.905, val_Loss: 575.083\n",
      "Epoch: 238, train_Loss: 123.798, val_Loss: 583.105\n",
      "Epoch: 239, train_Loss: 122.705, val_Loss: 576.294\n",
      "Epoch: 240, train_Loss: 126.143, val_Loss: 580.282\n",
      "Epoch: 241, train_Loss: 125.106, val_Loss: 566.563\n",
      "Epoch: 242, train_Loss: 124.230, val_Loss: 579.833\n",
      "Epoch: 243, train_Loss: 123.439, val_Loss: 567.925\n",
      "Epoch: 244, train_Loss: 121.638, val_Loss: 574.943\n",
      "Epoch: 245, train_Loss: 145.487, val_Loss: 582.143\n",
      "Epoch: 246, train_Loss: 137.047, val_Loss: 584.217\n",
      "Epoch: 247, train_Loss: 124.921, val_Loss: 594.193\n",
      "Epoch: 248, train_Loss: 116.067, val_Loss: 571.454\n",
      "Epoch: 249, train_Loss: 114.442, val_Loss: 578.613\n",
      "Epoch: 250, train_Loss: 111.952, val_Loss: 578.399\n",
      "Epoch: 251, train_Loss: 110.162, val_Loss: 571.294\n",
      "Epoch: 252, train_Loss: 114.443, val_Loss: 583.964\n",
      "Epoch: 253, train_Loss: 118.954, val_Loss: 571.995\n",
      "Epoch: 254, train_Loss: 113.379, val_Loss: 575.235\n",
      "Epoch: 255, train_Loss: 114.881, val_Loss: 572.350\n",
      "Epoch: 256, train_Loss: 112.137, val_Loss: 573.532\n",
      "Epoch: 257, train_Loss: 109.271, val_Loss: 580.000\n",
      "Epoch: 258, train_Loss: 108.284, val_Loss: 577.860\n",
      "Epoch: 259, train_Loss: 112.224, val_Loss: 579.200\n",
      "Epoch: 260, train_Loss: 110.785, val_Loss: 565.541\n",
      "Epoch: 261, train_Loss: 111.000, val_Loss: 585.063\n",
      "Epoch: 262, train_Loss: 111.322, val_Loss: 583.079\n",
      "Epoch: 263, train_Loss: 109.330, val_Loss: 582.134\n",
      "Epoch: 264, train_Loss: 109.717, val_Loss: 580.862\n",
      "Epoch: 265, train_Loss: 108.118, val_Loss: 578.480\n",
      "Epoch: 266, train_Loss: 105.690, val_Loss: 578.255\n",
      "Epoch: 267, train_Loss: 107.603, val_Loss: 574.720\n",
      "Epoch: 268, train_Loss: 108.564, val_Loss: 571.862\n",
      "Epoch: 269, train_Loss: 105.448, val_Loss: 586.179\n",
      "Epoch: 270, train_Loss: 106.822, val_Loss: 568.515\n",
      "Epoch: 271, train_Loss: 115.338, val_Loss: 578.790\n",
      "Epoch: 272, train_Loss: 127.053, val_Loss: 580.042\n",
      "Epoch: 273, train_Loss: 108.193, val_Loss: 585.703\n",
      "Epoch: 274, train_Loss: 103.143, val_Loss: 584.163\n",
      "Epoch: 275, train_Loss: 101.382, val_Loss: 578.544\n",
      "Epoch: 276, train_Loss: 99.053, val_Loss: 590.067\n",
      "Epoch: 277, train_Loss: 120.532, val_Loss: 595.560\n",
      "Epoch: 278, train_Loss: 106.988, val_Loss: 576.851\n",
      "Epoch: 279, train_Loss: 101.489, val_Loss: 579.374\n",
      "Epoch: 280, train_Loss: 99.320, val_Loss: 573.134\n",
      "Epoch: 281, train_Loss: 103.354, val_Loss: 575.224\n",
      "Epoch: 282, train_Loss: 98.263, val_Loss: 581.061\n",
      "Epoch: 283, train_Loss: 95.422, val_Loss: 584.831\n",
      "Epoch: 284, train_Loss: 94.578, val_Loss: 587.521\n",
      "Epoch: 285, train_Loss: 94.065, val_Loss: 582.255\n",
      "Epoch: 286, train_Loss: 96.200, val_Loss: 586.110\n",
      "Epoch: 287, train_Loss: 95.052, val_Loss: 574.882\n",
      "Epoch: 288, train_Loss: 95.378, val_Loss: 577.243\n",
      "Epoch: 289, train_Loss: 95.785, val_Loss: 590.235\n",
      "Epoch: 290, train_Loss: 96.039, val_Loss: 580.080\n",
      "Epoch: 291, train_Loss: 94.076, val_Loss: 591.443\n",
      "Epoch: 292, train_Loss: 93.575, val_Loss: 591.521\n",
      "Epoch: 293, train_Loss: 94.326, val_Loss: 585.111\n",
      "Epoch: 294, train_Loss: 94.189, val_Loss: 567.386\n",
      "Epoch: 295, train_Loss: 92.408, val_Loss: 576.980\n",
      "Epoch: 296, train_Loss: 91.218, val_Loss: 580.432\n",
      "Epoch: 297, train_Loss: 94.646, val_Loss: 572.090\n",
      "Epoch: 298, train_Loss: 91.846, val_Loss: 579.233\n",
      "Epoch: 299, train_Loss: 92.089, val_Loss: 573.662\n",
      "Epoch: 300, train_Loss: 98.712, val_Loss: 590.943\n",
      "Epoch: 301, train_Loss: 93.587, val_Loss: 580.841\n",
      "Epoch: 302, train_Loss: 91.249, val_Loss: 584.133\n",
      "Epoch: 303, train_Loss: 91.110, val_Loss: 572.454\n",
      "Epoch: 304, train_Loss: 88.980, val_Loss: 578.981\n",
      "Epoch: 305, train_Loss: 87.857, val_Loss: 578.247\n",
      "Epoch: 306, train_Loss: 89.386, val_Loss: 580.865\n",
      "Epoch: 307, train_Loss: 88.896, val_Loss: 592.053\n",
      "Epoch: 308, train_Loss: 93.029, val_Loss: 575.104\n",
      "Epoch: 309, train_Loss: 93.903, val_Loss: 570.871\n",
      "Epoch: 310, train_Loss: 91.335, val_Loss: 580.444\n",
      "Epoch: 311, train_Loss: 88.194, val_Loss: 573.841\n",
      "Epoch: 312, train_Loss: 84.152, val_Loss: 577.666\n",
      "Epoch: 313, train_Loss: 85.623, val_Loss: 578.789\n",
      "Epoch: 314, train_Loss: 85.325, val_Loss: 577.625\n",
      "Epoch: 315, train_Loss: 84.414, val_Loss: 573.202\n",
      "Epoch: 316, train_Loss: 90.206, val_Loss: 583.125\n",
      "Epoch: 317, train_Loss: 92.738, val_Loss: 587.867\n",
      "Epoch: 318, train_Loss: 88.270, val_Loss: 580.917\n",
      "Epoch: 319, train_Loss: 87.516, val_Loss: 576.325\n",
      "Epoch: 320, train_Loss: 84.270, val_Loss: 582.284\n",
      "Epoch: 321, train_Loss: 83.477, val_Loss: 569.740\n",
      "Epoch: 322, train_Loss: 97.983, val_Loss: 572.591\n",
      "Epoch: 323, train_Loss: 89.819, val_Loss: 573.679\n",
      "Epoch: 324, train_Loss: 85.064, val_Loss: 573.438\n",
      "Epoch: 325, train_Loss: 80.792, val_Loss: 573.208\n",
      "Epoch: 326, train_Loss: 80.475, val_Loss: 573.234\n",
      "Epoch: 327, train_Loss: 81.834, val_Loss: 570.385\n",
      "Epoch: 328, train_Loss: 85.957, val_Loss: 583.659\n",
      "Epoch: 329, train_Loss: 115.303, val_Loss: 578.500\n",
      "Epoch: 330, train_Loss: 93.075, val_Loss: 570.889\n",
      "Epoch: 331, train_Loss: 89.990, val_Loss: 564.192\n",
      "Epoch: 332, train_Loss: 84.569, val_Loss: 573.783\n",
      "Epoch: 333, train_Loss: 80.940, val_Loss: 576.767\n",
      "Epoch: 334, train_Loss: 76.866, val_Loss: 581.597\n",
      "Epoch: 335, train_Loss: 75.692, val_Loss: 584.766\n",
      "Epoch: 336, train_Loss: 76.996, val_Loss: 575.924\n",
      "Epoch: 337, train_Loss: 76.245, val_Loss: 573.223\n",
      "Epoch: 338, train_Loss: 76.826, val_Loss: 580.568\n",
      "Epoch: 339, train_Loss: 77.012, val_Loss: 569.895\n",
      "Epoch: 340, train_Loss: 74.965, val_Loss: 574.728\n",
      "Epoch: 341, train_Loss: 80.082, val_Loss: 574.351\n",
      "Epoch: 342, train_Loss: 88.143, val_Loss: 571.471\n",
      "Epoch: 343, train_Loss: 84.742, val_Loss: 578.093\n",
      "Epoch: 344, train_Loss: 75.983, val_Loss: 574.678\n",
      "Epoch: 345, train_Loss: 73.459, val_Loss: 574.598\n",
      "Epoch: 346, train_Loss: 72.989, val_Loss: 571.468\n",
      "Epoch: 347, train_Loss: 72.101, val_Loss: 577.259\n",
      "Epoch: 348, train_Loss: 84.836, val_Loss: 580.512\n",
      "Epoch: 349, train_Loss: 84.959, val_Loss: 585.594\n",
      "Epoch: 350, train_Loss: 85.871, val_Loss: 573.786\n",
      "Epoch: 351, train_Loss: 78.360, val_Loss: 574.041\n",
      "Epoch: 352, train_Loss: 73.347, val_Loss: 574.536\n",
      "Epoch: 353, train_Loss: 70.737, val_Loss: 573.034\n",
      "Epoch: 354, train_Loss: 70.188, val_Loss: 574.165\n",
      "Epoch: 355, train_Loss: 72.751, val_Loss: 578.600\n",
      "Epoch: 356, train_Loss: 71.382, val_Loss: 576.653\n",
      "Epoch: 357, train_Loss: 87.885, val_Loss: 589.736\n",
      "Epoch: 358, train_Loss: 80.180, val_Loss: 590.375\n",
      "Epoch: 359, train_Loss: 85.956, val_Loss: 571.118\n",
      "Epoch: 360, train_Loss: 82.965, val_Loss: 579.565\n",
      "Epoch: 361, train_Loss: 74.481, val_Loss: 580.555\n",
      "Epoch: 362, train_Loss: 68.815, val_Loss: 575.103\n",
      "Epoch: 363, train_Loss: 67.470, val_Loss: 576.932\n",
      "Epoch: 364, train_Loss: 69.423, val_Loss: 582.842\n",
      "Epoch: 365, train_Loss: 69.380, val_Loss: 580.171\n",
      "Epoch: 366, train_Loss: 70.314, val_Loss: 571.279\n",
      "Epoch: 367, train_Loss: 68.306, val_Loss: 573.905\n",
      "Epoch: 368, train_Loss: 67.533, val_Loss: 572.937\n",
      "Epoch: 369, train_Loss: 67.509, val_Loss: 592.889\n",
      "Epoch: 370, train_Loss: 71.861, val_Loss: 592.831\n",
      "Epoch: 371, train_Loss: 67.668, val_Loss: 592.141\n",
      "Epoch: 372, train_Loss: 69.634, val_Loss: 587.726\n",
      "Epoch: 373, train_Loss: 76.312, val_Loss: 582.386\n",
      "Epoch: 374, train_Loss: 70.608, val_Loss: 577.542\n",
      "Epoch: 375, train_Loss: 67.591, val_Loss: 579.787\n",
      "Epoch: 376, train_Loss: 65.638, val_Loss: 581.646\n",
      "Epoch: 377, train_Loss: 64.939, val_Loss: 578.281\n",
      "Epoch: 378, train_Loss: 71.766, val_Loss: 583.069\n",
      "Epoch: 379, train_Loss: 68.171, val_Loss: 581.990\n",
      "Epoch: 380, train_Loss: 66.044, val_Loss: 594.399\n",
      "Epoch: 381, train_Loss: 65.570, val_Loss: 586.341\n",
      "Epoch: 382, train_Loss: 69.245, val_Loss: 587.144\n",
      "Epoch: 383, train_Loss: 68.513, val_Loss: 584.261\n",
      "Epoch: 384, train_Loss: 65.739, val_Loss: 575.926\n",
      "Epoch: 385, train_Loss: 63.423, val_Loss: 581.080\n",
      "Epoch: 386, train_Loss: 61.974, val_Loss: 590.560\n",
      "Epoch: 387, train_Loss: 63.829, val_Loss: 585.237\n",
      "Epoch: 388, train_Loss: 77.811, val_Loss: 580.124\n",
      "Epoch: 389, train_Loss: 68.957, val_Loss: 580.575\n",
      "Epoch: 390, train_Loss: 64.369, val_Loss: 585.281\n",
      "Epoch: 391, train_Loss: 64.205, val_Loss: 587.028\n",
      "Epoch: 392, train_Loss: 63.124, val_Loss: 577.117\n",
      "Epoch: 393, train_Loss: 62.761, val_Loss: 581.356\n",
      "Epoch: 394, train_Loss: 60.165, val_Loss: 580.848\n",
      "Epoch: 395, train_Loss: 61.789, val_Loss: 578.800\n",
      "Epoch: 396, train_Loss: 62.398, val_Loss: 599.026\n",
      "Epoch: 397, train_Loss: 60.828, val_Loss: 582.085\n",
      "Epoch: 398, train_Loss: 64.280, val_Loss: 579.988\n",
      "Epoch: 399, train_Loss: 65.921, val_Loss: 581.394\n",
      "Epoch: 400, train_Loss: 68.182, val_Loss: 577.181\n",
      "Epoch: 401, train_Loss: 62.295, val_Loss: 575.503\n",
      "Epoch: 402, train_Loss: 60.607, val_Loss: 570.512\n",
      "Epoch: 403, train_Loss: 60.166, val_Loss: 566.743\n",
      "Epoch: 404, train_Loss: 60.855, val_Loss: 566.454\n",
      "Epoch: 405, train_Loss: 59.844, val_Loss: 568.280\n",
      "Epoch: 406, train_Loss: 59.392, val_Loss: 572.784\n",
      "Epoch: 407, train_Loss: 60.612, val_Loss: 562.201\n",
      "Epoch: 408, train_Loss: 60.441, val_Loss: 573.338\n",
      "Epoch: 409, train_Loss: 65.843, val_Loss: 574.557\n",
      "Epoch: 410, train_Loss: 65.701, val_Loss: 573.382\n",
      "Epoch: 411, train_Loss: 61.638, val_Loss: 585.019\n",
      "Epoch: 412, train_Loss: 59.836, val_Loss: 570.329\n",
      "Epoch: 413, train_Loss: 57.897, val_Loss: 581.549\n",
      "Epoch: 414, train_Loss: 59.621, val_Loss: 582.990\n",
      "Epoch: 415, train_Loss: 61.224, val_Loss: 573.147\n",
      "Epoch: 416, train_Loss: 60.545, val_Loss: 571.049\n",
      "Epoch: 417, train_Loss: 62.417, val_Loss: 572.604\n",
      "Epoch: 418, train_Loss: 59.787, val_Loss: 574.944\n",
      "Epoch: 419, train_Loss: 59.944, val_Loss: 566.188\n",
      "Epoch: 420, train_Loss: 59.918, val_Loss: 584.228\n",
      "Epoch: 421, train_Loss: 62.699, val_Loss: 570.970\n",
      "Epoch: 422, train_Loss: 58.285, val_Loss: 574.284\n",
      "Epoch: 423, train_Loss: 58.444, val_Loss: 578.729\n",
      "Epoch: 424, train_Loss: 58.292, val_Loss: 578.213\n",
      "Epoch: 425, train_Loss: 59.487, val_Loss: 576.571\n",
      "Epoch: 426, train_Loss: 65.465, val_Loss: 581.159\n",
      "Epoch: 427, train_Loss: 66.349, val_Loss: 583.333\n",
      "Epoch: 428, train_Loss: 62.818, val_Loss: 571.449\n",
      "Epoch: 429, train_Loss: 59.962, val_Loss: 572.942\n",
      "Epoch: 430, train_Loss: 59.533, val_Loss: 571.006\n",
      "Epoch: 431, train_Loss: 54.320, val_Loss: 568.676\n",
      "Epoch: 432, train_Loss: 53.570, val_Loss: 571.577\n",
      "Epoch: 433, train_Loss: 53.158, val_Loss: 571.764\n",
      "Epoch: 434, train_Loss: 55.180, val_Loss: 573.437\n",
      "Epoch: 435, train_Loss: 54.452, val_Loss: 563.749\n",
      "Epoch: 436, train_Loss: 54.824, val_Loss: 573.052\n",
      "Epoch: 437, train_Loss: 55.103, val_Loss: 570.469\n",
      "Epoch: 438, train_Loss: 62.944, val_Loss: 575.544\n",
      "Epoch: 439, train_Loss: 61.237, val_Loss: 584.304\n",
      "Epoch: 440, train_Loss: 64.029, val_Loss: 570.324\n",
      "Epoch: 441, train_Loss: 67.759, val_Loss: 565.255\n",
      "Epoch: 442, train_Loss: 67.379, val_Loss: 568.344\n",
      "Epoch: 443, train_Loss: 60.795, val_Loss: 567.024\n",
      "Epoch: 444, train_Loss: 57.070, val_Loss: 563.971\n",
      "Epoch: 445, train_Loss: 53.595, val_Loss: 565.409\n",
      "Epoch: 446, train_Loss: 52.916, val_Loss: 575.999\n",
      "Epoch: 447, train_Loss: 53.166, val_Loss: 562.769\n",
      "Epoch: 448, train_Loss: 51.628, val_Loss: 575.828\n",
      "Epoch: 449, train_Loss: 51.785, val_Loss: 571.574\n",
      "Epoch: 450, train_Loss: 51.524, val_Loss: 564.674\n",
      "Epoch: 451, train_Loss: 60.597, val_Loss: 585.828\n",
      "Epoch: 452, train_Loss: 64.008, val_Loss: 575.594\n",
      "Epoch: 453, train_Loss: 56.433, val_Loss: 568.911\n",
      "Epoch: 454, train_Loss: 52.932, val_Loss: 562.427\n",
      "Epoch: 455, train_Loss: 52.021, val_Loss: 568.591\n",
      "Epoch: 456, train_Loss: 50.662, val_Loss: 566.549\n",
      "Epoch: 457, train_Loss: 49.374, val_Loss: 566.818\n",
      "Epoch: 458, train_Loss: 48.698, val_Loss: 566.161\n",
      "Epoch: 459, train_Loss: 49.534, val_Loss: 566.875\n",
      "Epoch: 460, train_Loss: 51.127, val_Loss: 572.986\n",
      "Epoch: 461, train_Loss: 50.286, val_Loss: 571.898\n",
      "Epoch: 462, train_Loss: 50.469, val_Loss: 565.606\n",
      "Epoch: 463, train_Loss: 50.391, val_Loss: 566.270\n",
      "Epoch: 464, train_Loss: 53.639, val_Loss: 568.982\n",
      "Epoch: 465, train_Loss: 55.740, val_Loss: 571.077\n",
      "Epoch: 466, train_Loss: 55.488, val_Loss: 577.236\n",
      "Epoch: 467, train_Loss: 51.932, val_Loss: 577.742\n",
      "Epoch: 468, train_Loss: 50.565, val_Loss: 572.406\n",
      "Epoch: 469, train_Loss: 50.365, val_Loss: 560.469\n",
      "Epoch: 470, train_Loss: 51.596, val_Loss: 568.457\n",
      "Epoch: 471, train_Loss: 51.890, val_Loss: 570.497\n",
      "Epoch: 472, train_Loss: 50.162, val_Loss: 568.236\n",
      "Epoch: 473, train_Loss: 49.465, val_Loss: 564.356\n",
      "Epoch: 474, train_Loss: 48.935, val_Loss: 567.574\n",
      "Epoch: 475, train_Loss: 51.962, val_Loss: 570.700\n",
      "Epoch: 476, train_Loss: 51.382, val_Loss: 568.051\n",
      "Epoch: 477, train_Loss: 49.362, val_Loss: 570.390\n",
      "Epoch: 478, train_Loss: 49.730, val_Loss: 565.493\n",
      "Epoch: 479, train_Loss: 48.816, val_Loss: 568.511\n",
      "Epoch: 480, train_Loss: 47.350, val_Loss: 572.204\n",
      "Epoch: 481, train_Loss: 47.278, val_Loss: 576.631\n",
      "Epoch: 482, train_Loss: 50.715, val_Loss: 571.389\n",
      "Epoch: 483, train_Loss: 49.673, val_Loss: 566.527\n",
      "Epoch: 484, train_Loss: 49.730, val_Loss: 573.689\n",
      "Epoch: 485, train_Loss: 47.902, val_Loss: 571.270\n",
      "Epoch: 486, train_Loss: 50.376, val_Loss: 582.109\n",
      "Epoch: 487, train_Loss: 57.145, val_Loss: 577.483\n",
      "Epoch: 488, train_Loss: 51.316, val_Loss: 574.625\n",
      "Epoch: 489, train_Loss: 49.662, val_Loss: 571.844\n",
      "Epoch: 490, train_Loss: 49.040, val_Loss: 574.530\n",
      "Epoch: 491, train_Loss: 46.124, val_Loss: 576.675\n",
      "Epoch: 492, train_Loss: 45.081, val_Loss: 562.963\n",
      "Epoch: 493, train_Loss: 44.609, val_Loss: 568.440\n",
      "Epoch: 494, train_Loss: 45.125, val_Loss: 569.590\n",
      "Epoch: 495, train_Loss: 46.247, val_Loss: 572.641\n",
      "Epoch: 496, train_Loss: 45.741, val_Loss: 575.096\n",
      "Epoch: 497, train_Loss: 46.387, val_Loss: 572.077\n",
      "Epoch: 498, train_Loss: 49.019, val_Loss: 567.392\n",
      "Epoch: 499, train_Loss: 74.611, val_Loss: 585.132\n",
      "Epoch: 500, train_Loss: 91.039, val_Loss: 584.653\n"
     ]
    }
   ],
   "source": [
    "model = bid_LSTM_Predictor(dataset)\n",
    "model = model.to(device)\n",
    "train_losses, val_losses = train(dataset, train_dataset, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27a7152e-3438-43f2-9432-f1b189df9404",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predect(dataset, test_dataset, model):\n",
    "    model.eval()\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=5, drop_last=True)\n",
    "\n",
    "    index = np.random.choice(len(test_dataloader))\n",
    "    \n",
    "    for batch, (x, y) in enumerate(test_dataloader):\n",
    "    \n",
    "        smiles, wavelength = x, y\n",
    "        break\n",
    "    state_h, state_c = model.init_state(5)\n",
    "    state_h = state_h.to(device)\n",
    "    state_c = state_c.to(device)\n",
    "    y_pred, (state_h, state_c) = model(smiles.to(device), (state_h, state_c))\n",
    "    y_pred_permute = torch.permute(y_pred, (2, 1, 0))    \n",
    "\n",
    "    print(y_pred_permute)\n",
    "    print(wavelength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df41f473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[293.2987, 267.6434, 278.4007, 256.0234, 276.9870],\n",
      "         [321.8479, 275.3440, 273.6069, 269.2428, 256.1450],\n",
      "         [300.1446, 279.2351, 282.4070, 284.6063, 279.7379],\n",
      "         [317.2028, 278.2509, 273.0488, 274.4804, 269.0142],\n",
      "         [356.6292, 285.6224, 285.7785, 303.7660, 284.8510],\n",
      "         [390.0320, 305.2563, 285.2646, 319.2489, 283.6737],\n",
      "         [416.0647, 307.8445, 289.5027, 335.2115, 302.5531],\n",
      "         [445.2879, 292.4807, 318.6165, 345.7350, 304.5890],\n",
      "         [524.6326, 277.8245, 304.8239, 364.0375, 327.6816],\n",
      "         [532.2744, 270.4221, 311.9603, 377.1744, 366.8730],\n",
      "         [597.3447, 302.8230, 330.0548, 390.7117, 416.8093],\n",
      "         [629.3893, 316.4822, 334.5509, 450.9218, 420.8423],\n",
      "         [623.5237, 329.3792, 340.8045, 433.6453, 448.2572],\n",
      "         [583.2706, 357.2257, 343.1219, 397.3820, 417.2019],\n",
      "         [548.2797, 351.6292, 308.0952, 354.6483, 423.2553],\n",
      "         [554.1119, 363.6640, 319.6273, 367.8444, 422.0349],\n",
      "         [535.3646, 367.4387, 349.8966, 331.8230, 450.0142],\n",
      "         [535.7385, 402.7800, 336.5702, 356.4386, 450.2560],\n",
      "         [534.1064, 397.0421, 331.5762, 372.7046, 464.0066],\n",
      "         [561.0001, 405.1998, 362.2565, 371.0797, 465.2337],\n",
      "         [553.2569, 410.7116, 444.4835, 365.4410, 457.5878],\n",
      "         [538.4617, 416.8520, 448.4771, 368.9445, 435.4827],\n",
      "         [507.1273, 425.2232, 443.5925, 392.7577, 439.8313],\n",
      "         [508.8846, 459.1926, 467.0820, 382.8676, 433.2195],\n",
      "         [494.6641, 453.4061, 442.2290, 395.3141, 462.2231],\n",
      "         [491.1427, 462.4842, 437.4822, 399.4113, 442.3775],\n",
      "         [488.4955, 517.1863, 435.7699, 402.5579, 469.3061],\n",
      "         [476.5364, 580.4030, 441.1737, 398.2113, 490.4264],\n",
      "         [461.4785, 582.8813, 422.0498, 410.3587, 480.9380],\n",
      "         [471.9021, 554.7853, 413.9734, 402.9287, 486.8780],\n",
      "         [472.3461, 518.1909, 406.6817, 408.8790, 521.5020],\n",
      "         [482.2035, 499.8157, 424.3553, 408.0291, 567.0043],\n",
      "         [486.8916, 482.6716, 413.1434, 407.9625, 551.2643],\n",
      "         [502.7491, 459.4660, 397.5394, 416.1977, 511.7473],\n",
      "         [494.5012, 434.2074, 414.7276, 406.4240, 534.7095],\n",
      "         [478.5966, 430.9064, 429.8572, 401.6909, 562.5206],\n",
      "         [474.1801, 430.8314, 438.8231, 412.2382, 599.3721],\n",
      "         [460.1754, 428.2263, 438.4308, 426.0041, 605.4490],\n",
      "         [453.9799, 425.8259, 415.7867, 400.7329, 562.5231],\n",
      "         [448.7307, 429.8663, 399.0912, 383.8522, 555.0103],\n",
      "         [444.5734, 430.6269, 419.1795, 365.6272, 542.7470],\n",
      "         [442.6154, 422.5909, 427.2419, 353.2369, 517.8819],\n",
      "         [430.9016, 413.4414, 454.0598, 353.2311, 502.2432],\n",
      "         [416.1021, 404.1498, 533.6131, 345.2528, 490.3023],\n",
      "         [404.0441, 396.4516, 529.2007, 345.1917, 466.4749],\n",
      "         [392.0140, 386.3033, 484.4927, 351.7219, 451.3015],\n",
      "         [381.3169, 370.2549, 452.6036, 351.0520, 439.9756],\n",
      "         [372.5080, 358.7518, 421.3672, 344.7949, 432.8790],\n",
      "         [364.5910, 350.1152, 404.1608, 329.4133, 425.0468],\n",
      "         [358.9009, 346.5793, 392.8331, 319.2581, 417.1770],\n",
      "         [355.7003, 342.6842, 379.0902, 317.9898, 412.5700],\n",
      "         [348.2543, 337.6179, 367.6643, 314.6269, 406.0999],\n",
      "         [343.4259, 331.4246, 359.7048, 313.0414, 400.9124],\n",
      "         [340.8110, 327.4641, 354.5758, 312.9200, 390.0432],\n",
      "         [339.6678, 326.2577, 349.1067, 314.6776, 379.9879],\n",
      "         [338.9633, 326.3549, 342.9429, 315.7024, 373.7478],\n",
      "         [337.6693, 326.4261, 339.9991, 314.5839, 369.5615],\n",
      "         [335.4890, 327.2330, 338.7790, 313.9290, 365.3475],\n",
      "         [334.8003, 327.5706, 337.8058, 315.1343, 360.8042],\n",
      "         [334.4935, 327.6813, 336.5094, 315.6798, 355.3476],\n",
      "         [334.2831, 326.2399, 335.0800, 312.8793, 351.6651],\n",
      "         [333.7668, 324.3337, 334.1409, 308.0303, 350.2560],\n",
      "         [331.3100, 324.3434, 333.4686, 305.7921, 349.3269],\n",
      "         [327.7339, 322.9583, 333.1250, 304.9426, 348.0647],\n",
      "         [325.3139, 322.7896, 332.2973, 304.7841, 345.9239],\n",
      "         [325.7114, 323.1427, 331.0316, 304.1935, 344.4376],\n",
      "         [327.4203, 322.8354, 328.6047, 302.3857, 343.4174],\n",
      "         [328.2078, 320.9357, 325.8251, 301.1479, 342.3944],\n",
      "         [328.0911, 320.2125, 323.3957, 301.6848, 341.7633],\n",
      "         [328.0310, 319.8925, 321.2510, 302.4851, 341.7298],\n",
      "         [329.5133, 320.3492, 319.6699, 303.0692, 341.8811],\n",
      "         [332.6433, 321.7822, 320.6967, 304.4797, 342.0154],\n",
      "         [344.2939, 328.6445, 322.7273, 309.3020, 342.6393],\n",
      "         [352.9355, 342.5849, 326.1033, 313.9519, 343.9777],\n",
      "         [356.5974, 345.3130, 335.3833, 314.7899, 344.9167],\n",
      "         [358.0813, 346.2357, 348.2961, 314.0878, 347.1902],\n",
      "         [361.4627, 348.0753, 351.2861, 312.2723, 352.8592],\n",
      "         [358.0863, 345.5073, 356.5907, 312.0348, 365.1110],\n",
      "         [301.0935, 289.0953, 311.3174, 256.6324, 329.7830]]], device='cuda:0',\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "tensor([320.1200, 275.1200, 337.2000, 257.5100, 387.2400])\n"
     ]
    }
   ],
   "source": [
    "predect(dataset, test_dataset, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc12867b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12,4))\n",
    "axes[0].plot(train_losses, label=\"train_Loss\")\n",
    "axes[0].plot(val_losses, label=\"val_Loss\")\n",
    "axes[0].grid()\n",
    "axes[0].set_xlabel(\"epoch\")\n",
    "axes[0].legend()\n",
    "\n",
    "\n",
    "axes[1].plot(train_losses, label=\"train_Loss\")\n",
    "axes[1].plot(val_losses, label=\"val_Loss\")\n",
    "axes[1].grid()\n",
    "axes[1].set_yscale('log')\n",
    "axes[1].set_xlabel(\"epoch\")\n",
    "axes[1].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7de8ccd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataset, test_dataset, model):\n",
    "    model.eval()\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=len(test_dataset), drop_last=True)\n",
    "    \n",
    "    criterion = torch.nn.L1Loss()\n",
    "    \n",
    "    total_loss = 0\n",
    "    state_h, state_c = model.init_state(len(test_dataset))\n",
    "    state_h = state_h.to(device)\n",
    "    state_c = state_c.to(device)\n",
    "    \n",
    "    for batch, (x, y) in enumerate(test_dataloader):\n",
    "    \n",
    "        y_pred, (state_h, state_c) = model(x.to(device), (state_h, state_c))\n",
    "        y_pred_permute = torch.permute(y_pred, (2, 1, 0))    \n",
    "        loss = criterion(y_pred_permute[0, dataset.max_length-1], y.to(device))\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        state_h = state_h.detach()\n",
    "        state_c = state_c.detach()\n",
    "    \n",
    "    return total_loss\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e566e266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_Loss: 25.054\n"
     ]
    }
   ],
   "source": [
    "print(\"test_Loss: {:.3f}\".format(test(dataset, test_dataset, model)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7de8ccd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataset, test_dataset, model):\n",
    "    model.eval()\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=len(test_dataset), drop_last=True)\n",
    "    \n",
    "    criterion = torch.nn.MSELoss()\n",
    "    \n",
    "    total_loss = 0\n",
    "    state_h, state_c = model.init_state(len(test_dataset))\n",
    "    state_h = state_h.to(device)\n",
    "    state_c = state_c.to(device)\n",
    "    \n",
    "    for batch, (x, y) in enumerate(test_dataloader):\n",
    "    \n",
    "        y_pred, (state_h, state_c) = model(x.to(device), (state_h, state_c))\n",
    "        y_pred_permute = torch.permute(y_pred, (2, 1, 0))    \n",
    "        loss = criterion(y_pred_permute[0, dataset.max_length-1], y.to(device))\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        state_h = state_h.detach()\n",
    "        state_c = state_c.detach()\n",
    "    \n",
    "    return total_loss\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e566e266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_Loss: 1315.040\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m現在のセルまたは前のセルでコードを実行中に、カーネルがクラッシュしました。エラーの原因を特定するには、セル内のコードを確認してください。詳細については、<a href='https://aka.ms/vscodeJupyterKernelCrash'>こちら</a> をクリックしてください。さらなる詳細については、Jupyter [log] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "print(\"test_Loss: {:.3f}\".format(test(dataset, test_dataset, model)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 | packaged by conda-forge | (main, Aug 22 2022, 20:35:26) [GCC 10.4.0]"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
