{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f4e8431b-5b14-4ce0-8d52-8eece073a588",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_EPOCHS = 500\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 0.001\n",
    "SMILES_COL = 'Column3'\n",
    "WAVELENGTH_COL = 'Column5'\n",
    "URL = '/home/ishii/graduation_research/data/csvファイル/dft_B3LYP_6-31G*_zinc_for-sale_1000000_0to100000.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ca771bf3-36b2-4fec-836d-266ac0d51e60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#変更後のデータセット\n",
    "import torch\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, url, smiles_col, wavelength_col):\n",
    "        self.max_length = 0\n",
    "        self.dummy_char = '_'\n",
    "        \n",
    "        self.url = url\n",
    "        self.smiles_col = smiles_col\n",
    "        self.smiles = []\n",
    "        self.words = self.load_words()\n",
    "        self.uniq_words = self.get_uniq_words()\n",
    "        self.index_to_word = {index: word for index, word in enumerate(self.uniq_words)}\n",
    "        self.word_to_index = {word: index for index, word in enumerate(self.uniq_words)}\n",
    "        self.words_indexes = [self.word_to_index[w] for w in self.words]\n",
    "\n",
    "        self.wavelength_col = wavelength_col\n",
    "        self.wavelengths = []\n",
    "        self.items = self.generate_items()\n",
    "        \n",
    "        self.dummmy_index = self.word_to_index[self.dummy_char]\n",
    "\n",
    "    def load_words(self):\n",
    "        train_df = pd.read_csv(self.url, usecols=[SMILES_COL])\n",
    "        self.smiles = list(train_df[self.smiles_col])\n",
    "        for i, smile in enumerate(self.smiles):\n",
    "            new_smile = smile[1:]\n",
    "            self.smiles[i] = new_smile\n",
    "        self.max_length = max(len(smile) for smile in self.smiles)\n",
    "        self.smiles = list(smile.ljust(self.max_length, self.dummy_char) for smile in self.smiles)\n",
    "        train_df = pd.Series(self.smiles)\n",
    "        text = train_df.str.cat(sep=' ')\n",
    "        text = \"\".join(text.split(' '))\n",
    "        return [text[i] for i in range(len(text))]\n",
    "    \n",
    "    def generate_items(self):\n",
    "        train_df = pd.read_csv(self.url, usecols=[WAVELENGTH_COL])\n",
    "        self.wavelengths = list(train_df[self.wavelength_col])\n",
    "        items = []\n",
    "        for i, smile in enumerate(self.smiles):\n",
    "            smile = list(smile)\n",
    "            items.append([self.word_to_index[w] for w in smile])\n",
    "        return items\n",
    "\n",
    "    def get_uniq_words(self):\n",
    "        word_counts = Counter(self.words)\n",
    "        return sorted(word_counts, key=word_counts.get, reverse=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.wavelengths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (\n",
    "            torch.tensor(self.items[index]),\n",
    "            torch.tensor(self.wavelengths[index])\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "281d2fdc-f4d5-4996-a3c7-0a2a265c21a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(url=URL, smiles_col=SMILES_COL, wavelength_col=WAVELENGTH_COL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b0267ec8-658a-4e5c-8b58-ba5a20136c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([ 6,  1,  5,  1,  1,  1,  3,  2, 20,  4,  1,  1,  5,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0]), tensor(248.7000))\n"
     ]
    }
   ],
   "source": [
    "print(dataset[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fd788f74-7bb4-4c23-ab60-18fb3f15af08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87628\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c80b1a8d-0167-41db-b0d3-c46072e6e02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ff953cc2-a21b-4620-b448-7d5395224691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 6,  1,  5,  1,  1,  1,  1,  3,  6,  4,  1,  5,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 6,  1,  5,  1,  1,  1,  3,  2, 20,  4,  1,  1,  5,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0]])\n",
      "tensor([239.7600, 248.7000])\n",
      "tensor([[ 2,  8,  2,  3,  2, 23,  9,  4,  2,  3,  8,  6,  4,  6,  2,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 2,  1,  5,  1, 10,  1,  3,  2,  4,  1, 10,  5,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0]])\n",
      "tensor([277.4000, 305.1800])\n",
      "tensor([[ 2,  1,  5, 10,  1,  1, 10,  1,  5,  2,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 9,  2,  1,  5,  1,  1,  1, 10,  1,  5,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0]])\n",
      "tensor([303.8400, 261.6700])\n",
      "tensor([[ 2,  1,  5,  1,  1,  3,  6,  4,  1,  1,  1,  5,  2, 20,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 2,  6,  1,  5,  1,  1,  1,  3,  6,  4,  1,  1,  5,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0]])\n",
      "tensor([251.6400, 259.0300])\n",
      "tensor([[ 6,  8,  2,  3,  6,  4,  1,  5,  1,  1,  1, 10,  1,  5,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 6,  8,  2,  3,  6,  4,  1,  5,  1,  1,  1,  1,  1,  5,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0]])\n",
      "tensor([287.6800, 263.9900])\n",
      "tensor([[ 9,  2,  2,  1,  5,  1,  1, 11, 10, 15, 12, 10,  5,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 9,  8,  2,  3,  6,  4,  1,  5,  1, 10,  1,  1, 10,  5,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0]])\n",
      "tensor([197.7500, 318.5700])\n",
      "tensor([[ 2,  2,  5,  3,  2,  4,  2,  6,  2,  3,  9,  4,  8,  9,  5,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 9,  1,  5, 10,  1, 10,  1,  7, 11, 10, 15, 12,  1, 10,  1,  5,  7,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0]])\n",
      "tensor([180.6400, 247.2000])\n",
      "tensor([[ 2,  6,  2,  3,  8,  6,  4,  1,  5,  1,  1,  1, 10,  1,  5,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 6,  8,  2,  3,  6,  4,  1,  5,  1,  1,  1, 11, 10, 24, 12,  3, 11,  6,\n",
      "         17, 12,  4,  1,  5,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0]])\n",
      "tensor([287.5600, 333.9000])\n",
      "tensor([[ 2,  1,  5,  1,  1,  3,  6,  4,  1,  1,  3,  2,  4,  1,  5,  2, 20,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 6,  8,  1,  5, 22,  1,  7,  1,  1,  3,  6,  4,  1,  1,  1,  7, 21,  5,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0]])\n",
      "tensor([247.8200, 259.8100])\n",
      "tensor([[ 6,  2,  1,  5,  1,  1,  1, 10,  1,  5,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 2,  1,  5,  1,  1,  3,  2,  4,  1,  3,  8,  6,  4, 11, 10, 15, 12, 10,\n",
      "          5,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0]])\n",
      "tensor([255.6200, 306.8800])\n",
      "tensor([[ 6,  1,  5, 10, 21,  1,  7,  1,  1,  3,  2, 20,  4,  1,  1,  1,  5,  7,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 9,  1,  5,  1,  1,  1,  1,  1,  5,  9,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0]])\n",
      "tensor([294.3600, 254.5300])\n"
     ]
    }
   ],
   "source": [
    "for batch, (x, y) in enumerate(dataloader):\n",
    "    print(x)\n",
    "    print(y)\n",
    "    if batch == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "963eec5a-0677-478b-8f00-91974d4e7ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#変更後のモデル\n",
    "import torch\n",
    "\n",
    "class LSTM_Predictor(torch.nn.Module):\n",
    "    def __init__(self, dataset):\n",
    "        super(LSTM_Predictor, self).__init__()\n",
    "        self.lstm_size = 128\n",
    "        self.embedding_dim = 128\n",
    "        self.num_layers = 3\n",
    "\n",
    "        n_vocab = len(dataset.uniq_words)\n",
    "        self.embedding = torch.nn.Embedding(\n",
    "            num_embeddings=n_vocab,\n",
    "            embedding_dim=self.embedding_dim,\n",
    "            #padding_idxの処理が不明確\n",
    "            #padding_idx=dataset.dummmy_index\n",
    "        )\n",
    "        self.lstm = torch.nn.LSTM(\n",
    "            input_size=self.lstm_size,\n",
    "            hidden_size=self.lstm_size,\n",
    "            num_layers=self.num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=0.2,\n",
    "        )\n",
    "        self.fc = torch.nn.Linear(self.lstm_size, 1)\n",
    "\n",
    "    def forward(self, x, prev_state):\n",
    "        embed = self.embedding(x)\n",
    "        output, state = self.lstm(embed, prev_state)\n",
    "        logits = self.fc(output)\n",
    "\n",
    "        return logits, state\n",
    "\n",
    "    def init_state(self, batch_size):\n",
    "        return (torch.zeros(self.num_layers, batch_size, self.lstm_size),\n",
    "                torch.zeros(self.num_layers, batch_size, self.lstm_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2cfd0211-c662-47bc-a69c-f76ddb5031c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#変更後の訓練プロセス\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def train(dataset, train_dataset, model):\n",
    "    losses = []\n",
    "    val_losses = []\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, drop_last=True)\n",
    "\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    \n",
    "    #scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2)\n",
    "\n",
    "    for epoch in range(MAX_EPOCHS):\n",
    "        model.train()\n",
    "        \n",
    "        state_h, state_c = model.init_state(BATCH_SIZE)\n",
    "        state_h = state_h.to(device)\n",
    "        state_c = state_c.to(device)\n",
    "        total_loss = 0\n",
    "        total_val_loss = 0\n",
    "\n",
    "        for batch, (x, y) in enumerate(train_dataloader):\n",
    "            if batch < int(len(train_dataloader) * 0.75):\n",
    "                model.train()\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                y_pred, (state_h, state_c) = model(x.to(device), (state_h, state_c))\n",
    "                y_pred_permute = torch.permute(y_pred, (2, 1, 0))\n",
    "                loss = criterion(y_pred_permute[0][dataset.max_length-1], y.to(device))\n",
    "                total_loss += loss.item()\n",
    "\n",
    "                state_h = state_h.detach()\n",
    "                state_c = state_c.detach()\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "            else:\n",
    "                model.eval()\n",
    "                \n",
    "                y_pred, (state_h, state_c) = model(x.to(device), (state_h, state_c))\n",
    "                y_pred_permute = torch.permute(y_pred, (2, 1, 0))\n",
    "                val_loss = criterion(y_pred_permute[0, dataset.max_length-1], y.to(device))\n",
    "                total_val_loss += val_loss.item()    \n",
    "                \n",
    "                state_h = state_h.detach()\n",
    "                state_c = state_c.detach()\n",
    "        \n",
    "        average_total_train_loss = total_loss / int(len(train_dataloader) * 0.75)\n",
    "        average_total_val_loss = total_val_loss / (len(train_dataloader) - int(len(train_dataloader) * 0.75))\n",
    "        \n",
    "        print(\"Epoch: {}, train_Loss: {:.3f}, val_Loss: {:.3f}\".format(\n",
    "            epoch+1, \n",
    "            average_total_train_loss,\n",
    "            average_total_val_loss\n",
    "        ))\n",
    "        losses.append(average_total_train_loss)\n",
    "        val_losses.append(average_total_val_loss)\n",
    "    return losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a67f788d-627e-42a1-89e3-38510896c476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"device: \" + str(device) + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3b912c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(url=URL, smiles_col=SMILES_COL, wavelength_col=WAVELENGTH_COL)\n",
    "n_samples = len(dataset)\n",
    "indices = list(range(n_samples))\n",
    "train_size = int(n_samples * 0.8)\n",
    "test_size = n_samples - train_size\n",
    "\n",
    "train_dataset = torch.utils.data.Subset(dataset, indices[:train_size])\n",
    "test_dataset = torch.utils.data.Subset(dataset, indices[train_size:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9e7f1ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70102\n",
      "17526\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset))\n",
    "print(len(test_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3d15e87d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "410\n",
      "137\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, drop_last=True)\n",
    "print(int(len(train_dataloader) * 0.75))\n",
    "print(len(train_dataloader) - int(len(train_dataloader) * 0.75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5b9ca541-5e56-4e0f-a42b-5c1b0ec0c701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, train_Loss: 83918.353, val_Loss: 67630.874\n",
      "Epoch: 2, train_Loss: 58088.973, val_Loss: 45932.134\n",
      "Epoch: 3, train_Loss: 39256.371, val_Loss: 30177.307\n",
      "Epoch: 4, train_Loss: 25712.751, val_Loss: 19098.839\n",
      "Epoch: 5, train_Loss: 16361.102, val_Loss: 11704.740\n",
      "Epoch: 6, train_Loss: 10273.351, val_Loss: 7118.494\n",
      "Epoch: 7, train_Loss: 6618.096, val_Loss: 4549.555\n",
      "Epoch: 8, train_Loss: 4651.543, val_Loss: 3302.352\n",
      "Epoch: 9, train_Loss: 3739.365, val_Loss: 2810.156\n",
      "Epoch: 10, train_Loss: 3393.314, val_Loss: 2671.277\n",
      "Epoch: 11, train_Loss: 3294.478, val_Loss: 2655.369\n",
      "Epoch: 12, train_Loss: 3277.204, val_Loss: 2664.517\n",
      "Epoch: 13, train_Loss: 3277.619, val_Loss: 2672.206\n",
      "Epoch: 14, train_Loss: 3279.135, val_Loss: 2676.459\n",
      "Epoch: 15, train_Loss: 3279.647, val_Loss: 2679.127\n",
      "Epoch: 16, train_Loss: 3279.513, val_Loss: 2681.138\n",
      "Epoch: 17, train_Loss: 3279.020, val_Loss: 2682.651\n",
      "Epoch: 18, train_Loss: 3278.280, val_Loss: 2683.641\n",
      "Epoch: 19, train_Loss: 3277.380, val_Loss: 2684.144\n",
      "Epoch: 20, train_Loss: 3276.423, val_Loss: 2684.281\n",
      "Epoch: 21, train_Loss: 3275.509, val_Loss: 2684.201\n",
      "Epoch: 22, train_Loss: 3274.709, val_Loss: 2684.023\n",
      "Epoch: 23, train_Loss: 3274.054, val_Loss: 2683.826\n",
      "Epoch: 24, train_Loss: 3273.546, val_Loss: 2683.651\n",
      "Epoch: 25, train_Loss: 3273.166, val_Loss: 2683.507\n",
      "Epoch: 26, train_Loss: 3272.891, val_Loss: 2683.398\n",
      "Epoch: 27, train_Loss: 3272.694, val_Loss: 2683.317\n",
      "Epoch: 28, train_Loss: 3272.556, val_Loss: 2683.259\n",
      "Epoch: 29, train_Loss: 3272.460, val_Loss: 2683.221\n",
      "Epoch: 30, train_Loss: 3272.394, val_Loss: 2683.192\n",
      "Epoch: 31, train_Loss: 3272.349, val_Loss: 2683.173\n",
      "Epoch: 32, train_Loss: 3272.317, val_Loss: 2683.159\n",
      "Epoch: 33, train_Loss: 3272.296, val_Loss: 2683.151\n",
      "Epoch: 34, train_Loss: 3272.281, val_Loss: 2683.144\n",
      "Epoch: 35, train_Loss: 3272.271, val_Loss: 2683.141\n",
      "Epoch: 36, train_Loss: 3272.264, val_Loss: 2683.136\n",
      "Epoch: 37, train_Loss: 3272.260, val_Loss: 2683.136\n",
      "Epoch: 38, train_Loss: 3272.257, val_Loss: 2683.132\n",
      "Epoch: 39, train_Loss: 3272.254, val_Loss: 2683.132\n",
      "Epoch: 40, train_Loss: 3272.253, val_Loss: 2683.131\n",
      "Epoch: 41, train_Loss: 3272.251, val_Loss: 2683.132\n",
      "Epoch: 42, train_Loss: 3272.251, val_Loss: 2683.132\n",
      "Epoch: 43, train_Loss: 3272.250, val_Loss: 2683.132\n",
      "Epoch: 44, train_Loss: 3272.250, val_Loss: 2683.132\n",
      "Epoch: 45, train_Loss: 3272.250, val_Loss: 2683.132\n",
      "Epoch: 46, train_Loss: 3272.250, val_Loss: 2683.132\n",
      "Epoch: 47, train_Loss: 3272.250, val_Loss: 2683.132\n",
      "Epoch: 48, train_Loss: 3272.250, val_Loss: 2683.132\n",
      "Epoch: 49, train_Loss: 3272.250, val_Loss: 2683.132\n",
      "Epoch: 50, train_Loss: 3323.114, val_Loss: 2680.957\n",
      "Epoch: 51, train_Loss: 3273.211, val_Loss: 2683.857\n",
      "Epoch: 52, train_Loss: 3273.772, val_Loss: 2683.825\n",
      "Epoch: 53, train_Loss: 3273.622, val_Loss: 2683.774\n",
      "Epoch: 54, train_Loss: 3273.509, val_Loss: 2683.734\n",
      "Epoch: 55, train_Loss: 3273.431, val_Loss: 2683.708\n",
      "Epoch: 56, train_Loss: 3273.377, val_Loss: 2683.692\n",
      "Epoch: 57, train_Loss: 3273.341, val_Loss: 2683.677\n",
      "Epoch: 58, train_Loss: 3273.316, val_Loss: 2683.670\n",
      "Epoch: 59, train_Loss: 3273.299, val_Loss: 2683.664\n",
      "Epoch: 60, train_Loss: 3273.287, val_Loss: 2683.660\n",
      "Epoch: 61, train_Loss: 3273.279, val_Loss: 2683.656\n",
      "Epoch: 62, train_Loss: 3273.273, val_Loss: 2683.654\n",
      "Epoch: 63, train_Loss: 3273.270, val_Loss: 2683.653\n",
      "Epoch: 64, train_Loss: 3273.268, val_Loss: 2683.652\n",
      "Epoch: 65, train_Loss: 3273.266, val_Loss: 2683.653\n",
      "Epoch: 66, train_Loss: 3273.265, val_Loss: 2683.653\n",
      "Epoch: 67, train_Loss: 3273.264, val_Loss: 2683.652\n",
      "Epoch: 68, train_Loss: 3273.263, val_Loss: 2683.652\n",
      "Epoch: 69, train_Loss: 3273.263, val_Loss: 2683.651\n",
      "Epoch: 70, train_Loss: 3273.263, val_Loss: 2683.651\n",
      "Epoch: 71, train_Loss: 3273.262, val_Loss: 2683.651\n",
      "Epoch: 72, train_Loss: 3273.262, val_Loss: 2683.651\n",
      "Epoch: 73, train_Loss: 3273.262, val_Loss: 2683.651\n",
      "Epoch: 74, train_Loss: 3273.262, val_Loss: 2683.651\n",
      "Epoch: 75, train_Loss: 3273.262, val_Loss: 2683.651\n",
      "Epoch: 76, train_Loss: 3273.262, val_Loss: 2683.651\n",
      "Epoch: 77, train_Loss: 3273.262, val_Loss: 2683.651\n",
      "Epoch: 78, train_Loss: 3273.262, val_Loss: 2683.651\n",
      "Epoch: 79, train_Loss: 3273.262, val_Loss: 2683.651\n",
      "Epoch: 80, train_Loss: 3280.195, val_Loss: 2679.209\n",
      "Epoch: 81, train_Loss: 3276.658, val_Loss: 2686.834\n",
      "Epoch: 82, train_Loss: 3274.211, val_Loss: 2683.761\n",
      "Epoch: 83, train_Loss: 3273.448, val_Loss: 2683.732\n",
      "Epoch: 84, train_Loss: 3273.441, val_Loss: 2683.731\n",
      "Epoch: 85, train_Loss: 3273.438, val_Loss: 2683.729\n",
      "Epoch: 86, train_Loss: 3273.432, val_Loss: 2683.728\n",
      "Epoch: 87, train_Loss: 3268.328, val_Loss: 2685.668\n",
      "Epoch: 88, train_Loss: 3275.359, val_Loss: 2683.056\n",
      "Epoch: 89, train_Loss: 3221.690, val_Loss: 2388.811\n",
      "Epoch: 90, train_Loss: 2516.976, val_Loss: 1655.429\n",
      "Epoch: 91, train_Loss: 1823.198, val_Loss: 1316.378\n",
      "Epoch: 92, train_Loss: 1575.147, val_Loss: 1164.043\n",
      "Epoch: 93, train_Loss: 1392.519, val_Loss: 1032.387\n",
      "Epoch: 94, train_Loss: 1276.877, val_Loss: 999.288\n",
      "Epoch: 95, train_Loss: 1197.265, val_Loss: 920.127\n",
      "Epoch: 96, train_Loss: 1147.460, val_Loss: 900.686\n",
      "Epoch: 97, train_Loss: 1071.069, val_Loss: 856.891\n",
      "Epoch: 98, train_Loss: 1045.754, val_Loss: 858.978\n",
      "Epoch: 99, train_Loss: 984.195, val_Loss: 812.935\n",
      "Epoch: 100, train_Loss: 964.250, val_Loss: 785.434\n",
      "Epoch: 101, train_Loss: 926.047, val_Loss: 774.705\n",
      "Epoch: 102, train_Loss: 878.830, val_Loss: 757.364\n",
      "Epoch: 103, train_Loss: 866.526, val_Loss: 743.250\n",
      "Epoch: 104, train_Loss: 837.984, val_Loss: 727.644\n",
      "Epoch: 105, train_Loss: 787.802, val_Loss: 700.178\n",
      "Epoch: 106, train_Loss: 764.858, val_Loss: 734.111\n",
      "Epoch: 107, train_Loss: 742.153, val_Loss: 725.353\n",
      "Epoch: 108, train_Loss: 706.086, val_Loss: 705.038\n",
      "Epoch: 109, train_Loss: 704.756, val_Loss: 669.132\n",
      "Epoch: 110, train_Loss: 670.855, val_Loss: 669.536\n",
      "Epoch: 111, train_Loss: 650.987, val_Loss: 671.355\n",
      "Epoch: 112, train_Loss: 622.927, val_Loss: 674.521\n",
      "Epoch: 113, train_Loss: 607.521, val_Loss: 654.754\n",
      "Epoch: 114, train_Loss: 580.224, val_Loss: 666.287\n",
      "Epoch: 115, train_Loss: 643.723, val_Loss: 650.090\n",
      "Epoch: 116, train_Loss: 580.347, val_Loss: 633.147\n",
      "Epoch: 117, train_Loss: 554.537, val_Loss: 635.437\n",
      "Epoch: 118, train_Loss: 571.234, val_Loss: 619.001\n",
      "Epoch: 119, train_Loss: 550.990, val_Loss: 634.600\n",
      "Epoch: 120, train_Loss: 539.669, val_Loss: 618.129\n",
      "Epoch: 121, train_Loss: 519.385, val_Loss: 635.597\n",
      "Epoch: 122, train_Loss: 524.037, val_Loss: 626.647\n",
      "Epoch: 123, train_Loss: 497.524, val_Loss: 612.995\n",
      "Epoch: 124, train_Loss: 489.429, val_Loss: 614.723\n",
      "Epoch: 125, train_Loss: 477.508, val_Loss: 611.713\n",
      "Epoch: 126, train_Loss: 461.883, val_Loss: 609.708\n",
      "Epoch: 127, train_Loss: 442.497, val_Loss: 602.483\n",
      "Epoch: 128, train_Loss: 449.805, val_Loss: 599.737\n",
      "Epoch: 129, train_Loss: 428.542, val_Loss: 609.994\n",
      "Epoch: 130, train_Loss: 433.906, val_Loss: 632.356\n",
      "Epoch: 131, train_Loss: 424.137, val_Loss: 606.995\n",
      "Epoch: 132, train_Loss: 438.474, val_Loss: 631.054\n",
      "Epoch: 133, train_Loss: 422.819, val_Loss: 625.938\n",
      "Epoch: 134, train_Loss: 414.025, val_Loss: 617.093\n",
      "Epoch: 135, train_Loss: 383.079, val_Loss: 592.282\n",
      "Epoch: 136, train_Loss: 382.190, val_Loss: 605.873\n",
      "Epoch: 137, train_Loss: 373.894, val_Loss: 601.546\n",
      "Epoch: 138, train_Loss: 369.733, val_Loss: 621.971\n",
      "Epoch: 139, train_Loss: 370.917, val_Loss: 623.088\n",
      "Epoch: 140, train_Loss: 363.096, val_Loss: 624.678\n",
      "Epoch: 141, train_Loss: 365.643, val_Loss: 607.675\n",
      "Epoch: 142, train_Loss: 358.430, val_Loss: 602.947\n",
      "Epoch: 143, train_Loss: 345.962, val_Loss: 609.748\n",
      "Epoch: 144, train_Loss: 367.690, val_Loss: 606.751\n",
      "Epoch: 145, train_Loss: 336.809, val_Loss: 603.585\n",
      "Epoch: 146, train_Loss: 328.802, val_Loss: 598.443\n",
      "Epoch: 147, train_Loss: 322.495, val_Loss: 588.073\n",
      "Epoch: 148, train_Loss: 321.330, val_Loss: 596.575\n",
      "Epoch: 149, train_Loss: 365.662, val_Loss: 610.451\n",
      "Epoch: 150, train_Loss: 325.813, val_Loss: 607.269\n",
      "Epoch: 151, train_Loss: 308.158, val_Loss: 598.664\n",
      "Epoch: 152, train_Loss: 330.957, val_Loss: 604.713\n",
      "Epoch: 153, train_Loss: 321.279, val_Loss: 597.482\n",
      "Epoch: 154, train_Loss: 314.094, val_Loss: 593.548\n",
      "Epoch: 155, train_Loss: 324.101, val_Loss: 586.795\n",
      "Epoch: 156, train_Loss: 300.488, val_Loss: 612.114\n",
      "Epoch: 157, train_Loss: 298.564, val_Loss: 591.119\n",
      "Epoch: 158, train_Loss: 293.383, val_Loss: 594.924\n",
      "Epoch: 159, train_Loss: 280.834, val_Loss: 582.866\n",
      "Epoch: 160, train_Loss: 279.246, val_Loss: 622.886\n",
      "Epoch: 161, train_Loss: 283.523, val_Loss: 602.915\n",
      "Epoch: 162, train_Loss: 285.894, val_Loss: 613.993\n",
      "Epoch: 163, train_Loss: 277.893, val_Loss: 595.153\n",
      "Epoch: 164, train_Loss: 273.512, val_Loss: 630.019\n",
      "Epoch: 165, train_Loss: 272.527, val_Loss: 687.376\n",
      "Epoch: 166, train_Loss: 309.244, val_Loss: 590.079\n",
      "Epoch: 167, train_Loss: 279.443, val_Loss: 589.170\n",
      "Epoch: 168, train_Loss: 263.264, val_Loss: 590.451\n",
      "Epoch: 169, train_Loss: 258.048, val_Loss: 578.285\n",
      "Epoch: 170, train_Loss: 256.043, val_Loss: 601.752\n",
      "Epoch: 171, train_Loss: 260.611, val_Loss: 597.407\n",
      "Epoch: 172, train_Loss: 255.630, val_Loss: 603.384\n",
      "Epoch: 173, train_Loss: 259.083, val_Loss: 607.514\n",
      "Epoch: 174, train_Loss: 251.785, val_Loss: 595.175\n",
      "Epoch: 175, train_Loss: 243.774, val_Loss: 599.914\n",
      "Epoch: 176, train_Loss: 243.901, val_Loss: 596.823\n",
      "Epoch: 177, train_Loss: 247.221, val_Loss: 600.437\n",
      "Epoch: 178, train_Loss: 239.456, val_Loss: 598.227\n",
      "Epoch: 179, train_Loss: 251.163, val_Loss: 610.533\n",
      "Epoch: 180, train_Loss: 249.486, val_Loss: 600.125\n",
      "Epoch: 181, train_Loss: 247.437, val_Loss: 605.005\n",
      "Epoch: 182, train_Loss: 236.638, val_Loss: 598.717\n",
      "Epoch: 183, train_Loss: 235.907, val_Loss: 632.216\n",
      "Epoch: 184, train_Loss: 233.597, val_Loss: 611.308\n",
      "Epoch: 185, train_Loss: 233.774, val_Loss: 604.085\n",
      "Epoch: 186, train_Loss: 226.602, val_Loss: 599.443\n",
      "Epoch: 187, train_Loss: 227.548, val_Loss: 610.450\n",
      "Epoch: 188, train_Loss: 225.354, val_Loss: 620.147\n",
      "Epoch: 189, train_Loss: 228.769, val_Loss: 613.767\n",
      "Epoch: 190, train_Loss: 217.765, val_Loss: 604.849\n",
      "Epoch: 191, train_Loss: 232.155, val_Loss: 625.840\n",
      "Epoch: 192, train_Loss: 226.644, val_Loss: 600.269\n",
      "Epoch: 193, train_Loss: 219.744, val_Loss: 594.158\n",
      "Epoch: 194, train_Loss: 231.449, val_Loss: 615.032\n",
      "Epoch: 195, train_Loss: 224.520, val_Loss: 607.461\n",
      "Epoch: 196, train_Loss: 219.526, val_Loss: 605.186\n",
      "Epoch: 197, train_Loss: 215.274, val_Loss: 617.275\n",
      "Epoch: 198, train_Loss: 211.618, val_Loss: 614.294\n",
      "Epoch: 199, train_Loss: 212.313, val_Loss: 611.773\n",
      "Epoch: 200, train_Loss: 212.127, val_Loss: 604.611\n",
      "Epoch: 201, train_Loss: 204.861, val_Loss: 614.472\n",
      "Epoch: 202, train_Loss: 217.271, val_Loss: 616.056\n",
      "Epoch: 203, train_Loss: 212.166, val_Loss: 621.279\n",
      "Epoch: 204, train_Loss: 206.667, val_Loss: 616.227\n",
      "Epoch: 205, train_Loss: 206.520, val_Loss: 619.516\n",
      "Epoch: 206, train_Loss: 202.442, val_Loss: 606.700\n",
      "Epoch: 207, train_Loss: 200.940, val_Loss: 623.047\n",
      "Epoch: 208, train_Loss: 213.445, val_Loss: 605.914\n",
      "Epoch: 209, train_Loss: 211.739, val_Loss: 603.862\n",
      "Epoch: 210, train_Loss: 202.613, val_Loss: 607.615\n",
      "Epoch: 211, train_Loss: 203.213, val_Loss: 636.434\n",
      "Epoch: 212, train_Loss: 196.829, val_Loss: 613.488\n",
      "Epoch: 213, train_Loss: 191.457, val_Loss: 623.289\n",
      "Epoch: 214, train_Loss: 191.248, val_Loss: 626.672\n",
      "Epoch: 215, train_Loss: 194.255, val_Loss: 608.051\n",
      "Epoch: 216, train_Loss: 187.964, val_Loss: 614.131\n",
      "Epoch: 217, train_Loss: 195.584, val_Loss: 613.003\n",
      "Epoch: 218, train_Loss: 188.585, val_Loss: 599.412\n",
      "Epoch: 219, train_Loss: 184.736, val_Loss: 606.987\n",
      "Epoch: 220, train_Loss: 184.917, val_Loss: 607.997\n",
      "Epoch: 221, train_Loss: 185.990, val_Loss: 611.783\n",
      "Epoch: 222, train_Loss: 189.255, val_Loss: 604.239\n",
      "Epoch: 223, train_Loss: 183.185, val_Loss: 604.677\n",
      "Epoch: 224, train_Loss: 184.105, val_Loss: 615.895\n",
      "Epoch: 225, train_Loss: 188.601, val_Loss: 619.622\n",
      "Epoch: 226, train_Loss: 186.850, val_Loss: 614.193\n",
      "Epoch: 227, train_Loss: 194.314, val_Loss: 622.391\n",
      "Epoch: 228, train_Loss: 190.147, val_Loss: 616.256\n",
      "Epoch: 229, train_Loss: 228.122, val_Loss: 614.455\n",
      "Epoch: 230, train_Loss: 222.194, val_Loss: 618.936\n",
      "Epoch: 231, train_Loss: 187.739, val_Loss: 616.664\n",
      "Epoch: 232, train_Loss: 213.680, val_Loss: 613.199\n",
      "Epoch: 233, train_Loss: 190.095, val_Loss: 602.847\n",
      "Epoch: 234, train_Loss: 180.264, val_Loss: 602.590\n",
      "Epoch: 235, train_Loss: 174.026, val_Loss: 607.025\n",
      "Epoch: 236, train_Loss: 169.494, val_Loss: 604.453\n",
      "Epoch: 237, train_Loss: 179.011, val_Loss: 616.696\n",
      "Epoch: 238, train_Loss: 173.480, val_Loss: 606.490\n",
      "Epoch: 239, train_Loss: 169.582, val_Loss: 602.990\n",
      "Epoch: 240, train_Loss: 168.701, val_Loss: 607.865\n",
      "Epoch: 241, train_Loss: 184.885, val_Loss: 595.137\n",
      "Epoch: 242, train_Loss: 175.871, val_Loss: 606.489\n",
      "Epoch: 243, train_Loss: 170.350, val_Loss: 608.083\n",
      "Epoch: 244, train_Loss: 170.297, val_Loss: 616.190\n",
      "Epoch: 245, train_Loss: 166.965, val_Loss: 608.188\n",
      "Epoch: 246, train_Loss: 171.228, val_Loss: 629.234\n",
      "Epoch: 247, train_Loss: 170.578, val_Loss: 603.781\n",
      "Epoch: 248, train_Loss: 165.454, val_Loss: 606.648\n",
      "Epoch: 249, train_Loss: 162.228, val_Loss: 612.085\n",
      "Epoch: 250, train_Loss: 170.126, val_Loss: 617.360\n",
      "Epoch: 251, train_Loss: 162.424, val_Loss: 594.815\n",
      "Epoch: 252, train_Loss: 171.316, val_Loss: 610.995\n",
      "Epoch: 253, train_Loss: 163.483, val_Loss: 603.773\n",
      "Epoch: 254, train_Loss: 161.236, val_Loss: 600.194\n",
      "Epoch: 255, train_Loss: 163.856, val_Loss: 599.084\n",
      "Epoch: 256, train_Loss: 159.574, val_Loss: 611.228\n",
      "Epoch: 257, train_Loss: 159.031, val_Loss: 616.895\n",
      "Epoch: 258, train_Loss: 246.870, val_Loss: 631.743\n",
      "Epoch: 259, train_Loss: 208.585, val_Loss: 598.635\n",
      "Epoch: 260, train_Loss: 185.476, val_Loss: 605.836\n",
      "Epoch: 261, train_Loss: 162.518, val_Loss: 606.442\n",
      "Epoch: 262, train_Loss: 154.675, val_Loss: 599.423\n",
      "Epoch: 263, train_Loss: 153.161, val_Loss: 610.541\n",
      "Epoch: 264, train_Loss: 148.198, val_Loss: 599.819\n",
      "Epoch: 265, train_Loss: 145.774, val_Loss: 608.317\n",
      "Epoch: 266, train_Loss: 155.095, val_Loss: 610.426\n",
      "Epoch: 267, train_Loss: 153.750, val_Loss: 619.760\n",
      "Epoch: 268, train_Loss: 154.576, val_Loss: 600.656\n",
      "Epoch: 269, train_Loss: 148.407, val_Loss: 607.954\n",
      "Epoch: 270, train_Loss: 147.964, val_Loss: 597.509\n",
      "Epoch: 271, train_Loss: 149.962, val_Loss: 601.355\n",
      "Epoch: 272, train_Loss: 155.709, val_Loss: 599.123\n",
      "Epoch: 273, train_Loss: 153.879, val_Loss: 602.504\n",
      "Epoch: 274, train_Loss: 147.555, val_Loss: 600.860\n",
      "Epoch: 275, train_Loss: 145.023, val_Loss: 622.268\n",
      "Epoch: 276, train_Loss: 147.356, val_Loss: 590.033\n",
      "Epoch: 277, train_Loss: 151.239, val_Loss: 594.925\n",
      "Epoch: 278, train_Loss: 158.043, val_Loss: 596.275\n",
      "Epoch: 279, train_Loss: 152.874, val_Loss: 601.204\n",
      "Epoch: 280, train_Loss: 142.944, val_Loss: 602.953\n",
      "Epoch: 281, train_Loss: 142.866, val_Loss: 595.043\n",
      "Epoch: 282, train_Loss: 149.339, val_Loss: 595.179\n",
      "Epoch: 283, train_Loss: 142.523, val_Loss: 603.802\n",
      "Epoch: 284, train_Loss: 141.288, val_Loss: 619.335\n",
      "Epoch: 285, train_Loss: 141.910, val_Loss: 615.094\n",
      "Epoch: 286, train_Loss: 146.129, val_Loss: 618.490\n",
      "Epoch: 287, train_Loss: 152.928, val_Loss: 613.546\n",
      "Epoch: 288, train_Loss: 161.141, val_Loss: 624.755\n",
      "Epoch: 289, train_Loss: 152.900, val_Loss: 609.718\n",
      "Epoch: 290, train_Loss: 151.271, val_Loss: 621.859\n",
      "Epoch: 291, train_Loss: 142.055, val_Loss: 610.442\n",
      "Epoch: 292, train_Loss: 136.933, val_Loss: 599.243\n",
      "Epoch: 293, train_Loss: 136.377, val_Loss: 607.622\n",
      "Epoch: 294, train_Loss: 132.318, val_Loss: 612.099\n",
      "Epoch: 295, train_Loss: 132.477, val_Loss: 597.600\n",
      "Epoch: 296, train_Loss: 140.935, val_Loss: 610.321\n",
      "Epoch: 297, train_Loss: 227.174, val_Loss: 616.860\n",
      "Epoch: 298, train_Loss: 190.148, val_Loss: 601.010\n",
      "Epoch: 299, train_Loss: 160.688, val_Loss: 608.867\n",
      "Epoch: 300, train_Loss: 148.125, val_Loss: 597.422\n",
      "Epoch: 301, train_Loss: 136.458, val_Loss: 599.019\n",
      "Epoch: 302, train_Loss: 131.187, val_Loss: 602.798\n",
      "Epoch: 303, train_Loss: 129.583, val_Loss: 598.685\n",
      "Epoch: 304, train_Loss: 131.235, val_Loss: 613.260\n",
      "Epoch: 305, train_Loss: 138.747, val_Loss: 619.496\n",
      "Epoch: 306, train_Loss: 134.812, val_Loss: 610.291\n",
      "Epoch: 307, train_Loss: 133.152, val_Loss: 598.296\n",
      "Epoch: 308, train_Loss: 134.762, val_Loss: 601.906\n",
      "Epoch: 309, train_Loss: 131.328, val_Loss: 605.190\n",
      "Epoch: 310, train_Loss: 128.612, val_Loss: 601.359\n",
      "Epoch: 311, train_Loss: 130.931, val_Loss: 612.138\n",
      "Epoch: 312, train_Loss: 131.781, val_Loss: 605.544\n",
      "Epoch: 313, train_Loss: 137.049, val_Loss: 625.011\n",
      "Epoch: 314, train_Loss: 131.739, val_Loss: 604.296\n",
      "Epoch: 315, train_Loss: 128.400, val_Loss: 609.869\n",
      "Epoch: 316, train_Loss: 131.155, val_Loss: 599.554\n",
      "Epoch: 317, train_Loss: 129.868, val_Loss: 595.440\n",
      "Epoch: 318, train_Loss: 130.717, val_Loss: 606.573\n",
      "Epoch: 319, train_Loss: 135.456, val_Loss: 610.417\n",
      "Epoch: 320, train_Loss: 140.275, val_Loss: 605.371\n",
      "Epoch: 321, train_Loss: 135.210, val_Loss: 615.832\n",
      "Epoch: 322, train_Loss: 129.308, val_Loss: 611.694\n",
      "Epoch: 323, train_Loss: 125.006, val_Loss: 603.526\n",
      "Epoch: 324, train_Loss: 123.404, val_Loss: 600.046\n",
      "Epoch: 325, train_Loss: 126.852, val_Loss: 607.296\n",
      "Epoch: 326, train_Loss: 123.910, val_Loss: 603.816\n",
      "Epoch: 327, train_Loss: 124.646, val_Loss: 603.438\n",
      "Epoch: 328, train_Loss: 124.578, val_Loss: 594.927\n",
      "Epoch: 329, train_Loss: 123.200, val_Loss: 599.748\n",
      "Epoch: 330, train_Loss: 122.795, val_Loss: 605.309\n",
      "Epoch: 331, train_Loss: 122.569, val_Loss: 591.186\n",
      "Epoch: 332, train_Loss: 127.116, val_Loss: 598.961\n",
      "Epoch: 333, train_Loss: 127.094, val_Loss: 601.231\n",
      "Epoch: 334, train_Loss: 130.065, val_Loss: 609.266\n",
      "Epoch: 335, train_Loss: 133.798, val_Loss: 619.534\n",
      "Epoch: 336, train_Loss: 130.131, val_Loss: 611.748\n",
      "Epoch: 337, train_Loss: 119.761, val_Loss: 606.762\n",
      "Epoch: 338, train_Loss: 119.633, val_Loss: 605.533\n",
      "Epoch: 339, train_Loss: 127.287, val_Loss: 602.332\n",
      "Epoch: 340, train_Loss: 127.171, val_Loss: 610.867\n",
      "Epoch: 341, train_Loss: 128.130, val_Loss: 612.728\n",
      "Epoch: 342, train_Loss: 125.735, val_Loss: 600.347\n",
      "Epoch: 343, train_Loss: 115.862, val_Loss: 596.384\n",
      "Epoch: 344, train_Loss: 115.093, val_Loss: 598.992\n",
      "Epoch: 345, train_Loss: 114.428, val_Loss: 599.872\n",
      "Epoch: 346, train_Loss: 119.210, val_Loss: 606.489\n",
      "Epoch: 347, train_Loss: 118.277, val_Loss: 600.355\n",
      "Epoch: 348, train_Loss: 119.113, val_Loss: 602.547\n",
      "Epoch: 349, train_Loss: 114.392, val_Loss: 612.813\n",
      "Epoch: 350, train_Loss: 115.833, val_Loss: 601.406\n",
      "Epoch: 351, train_Loss: 120.051, val_Loss: 586.621\n",
      "Epoch: 352, train_Loss: 143.176, val_Loss: 607.592\n",
      "Epoch: 353, train_Loss: 131.193, val_Loss: 610.080\n",
      "Epoch: 354, train_Loss: 118.070, val_Loss: 593.001\n",
      "Epoch: 355, train_Loss: 113.296, val_Loss: 583.721\n",
      "Epoch: 356, train_Loss: 109.254, val_Loss: 590.609\n",
      "Epoch: 357, train_Loss: 111.220, val_Loss: 587.992\n",
      "Epoch: 358, train_Loss: 120.657, val_Loss: 606.330\n",
      "Epoch: 359, train_Loss: 127.635, val_Loss: 597.821\n",
      "Epoch: 360, train_Loss: 121.200, val_Loss: 604.729\n",
      "Epoch: 361, train_Loss: 117.543, val_Loss: 594.445\n",
      "Epoch: 362, train_Loss: 115.758, val_Loss: 597.653\n",
      "Epoch: 363, train_Loss: 117.624, val_Loss: 587.747\n",
      "Epoch: 364, train_Loss: 113.457, val_Loss: 601.304\n",
      "Epoch: 365, train_Loss: 118.444, val_Loss: 593.572\n",
      "Epoch: 366, train_Loss: 117.451, val_Loss: 603.381\n",
      "Epoch: 367, train_Loss: 116.995, val_Loss: 604.702\n",
      "Epoch: 368, train_Loss: 112.436, val_Loss: 600.017\n",
      "Epoch: 369, train_Loss: 110.996, val_Loss: 608.127\n",
      "Epoch: 370, train_Loss: 113.642, val_Loss: 612.584\n",
      "Epoch: 371, train_Loss: 111.408, val_Loss: 594.923\n",
      "Epoch: 372, train_Loss: 113.354, val_Loss: 605.772\n",
      "Epoch: 373, train_Loss: 117.437, val_Loss: 603.094\n",
      "Epoch: 374, train_Loss: 112.896, val_Loss: 605.613\n",
      "Epoch: 375, train_Loss: 110.904, val_Loss: 596.314\n",
      "Epoch: 376, train_Loss: 110.181, val_Loss: 611.019\n",
      "Epoch: 377, train_Loss: 111.951, val_Loss: 601.796\n",
      "Epoch: 378, train_Loss: 107.012, val_Loss: 610.663\n",
      "Epoch: 379, train_Loss: 108.199, val_Loss: 604.406\n",
      "Epoch: 380, train_Loss: 115.760, val_Loss: 606.865\n",
      "Epoch: 381, train_Loss: 134.571, val_Loss: 613.007\n",
      "Epoch: 382, train_Loss: 128.417, val_Loss: 612.694\n",
      "Epoch: 383, train_Loss: 115.494, val_Loss: 604.576\n",
      "Epoch: 384, train_Loss: 111.485, val_Loss: 599.172\n",
      "Epoch: 385, train_Loss: 104.742, val_Loss: 594.031\n",
      "Epoch: 386, train_Loss: 104.204, val_Loss: 591.207\n",
      "Epoch: 387, train_Loss: 106.185, val_Loss: 604.372\n",
      "Epoch: 388, train_Loss: 115.231, val_Loss: 595.478\n",
      "Epoch: 389, train_Loss: 108.259, val_Loss: 604.836\n",
      "Epoch: 390, train_Loss: 102.386, val_Loss: 602.086\n",
      "Epoch: 391, train_Loss: 100.964, val_Loss: 592.462\n",
      "Epoch: 392, train_Loss: 108.794, val_Loss: 607.234\n",
      "Epoch: 393, train_Loss: 118.092, val_Loss: 605.642\n",
      "Epoch: 394, train_Loss: 120.188, val_Loss: 599.497\n",
      "Epoch: 395, train_Loss: 116.467, val_Loss: 600.843\n",
      "Epoch: 396, train_Loss: 107.570, val_Loss: 604.712\n",
      "Epoch: 397, train_Loss: 99.253, val_Loss: 595.868\n",
      "Epoch: 398, train_Loss: 102.221, val_Loss: 598.898\n",
      "Epoch: 399, train_Loss: 107.275, val_Loss: 594.566\n",
      "Epoch: 400, train_Loss: 103.664, val_Loss: 611.953\n",
      "Epoch: 401, train_Loss: 105.939, val_Loss: 606.320\n",
      "Epoch: 402, train_Loss: 106.787, val_Loss: 609.197\n",
      "Epoch: 403, train_Loss: 103.677, val_Loss: 608.905\n",
      "Epoch: 404, train_Loss: 100.041, val_Loss: 597.422\n",
      "Epoch: 405, train_Loss: 114.749, val_Loss: 605.861\n",
      "Epoch: 406, train_Loss: 105.294, val_Loss: 597.082\n",
      "Epoch: 407, train_Loss: 97.759, val_Loss: 601.081\n",
      "Epoch: 408, train_Loss: 98.989, val_Loss: 600.405\n",
      "Epoch: 409, train_Loss: 98.693, val_Loss: 604.444\n",
      "Epoch: 410, train_Loss: 98.443, val_Loss: 604.620\n",
      "Epoch: 411, train_Loss: 98.842, val_Loss: 600.354\n",
      "Epoch: 412, train_Loss: 98.951, val_Loss: 597.543\n",
      "Epoch: 413, train_Loss: 110.372, val_Loss: 612.985\n",
      "Epoch: 414, train_Loss: 106.132, val_Loss: 596.883\n",
      "Epoch: 415, train_Loss: 115.255, val_Loss: 601.672\n",
      "Epoch: 416, train_Loss: 112.484, val_Loss: 601.674\n",
      "Epoch: 417, train_Loss: 101.673, val_Loss: 594.650\n",
      "Epoch: 418, train_Loss: 99.196, val_Loss: 614.035\n",
      "Epoch: 419, train_Loss: 107.329, val_Loss: 604.174\n",
      "Epoch: 420, train_Loss: 111.789, val_Loss: 625.886\n",
      "Epoch: 421, train_Loss: 107.755, val_Loss: 597.437\n",
      "Epoch: 422, train_Loss: 100.852, val_Loss: 608.142\n",
      "Epoch: 423, train_Loss: 96.457, val_Loss: 603.904\n",
      "Epoch: 424, train_Loss: 98.047, val_Loss: 601.098\n",
      "Epoch: 425, train_Loss: 100.637, val_Loss: 606.381\n",
      "Epoch: 426, train_Loss: 107.086, val_Loss: 603.732\n",
      "Epoch: 427, train_Loss: 102.249, val_Loss: 601.616\n",
      "Epoch: 428, train_Loss: 114.562, val_Loss: 593.824\n",
      "Epoch: 429, train_Loss: 110.126, val_Loss: 598.398\n",
      "Epoch: 430, train_Loss: 105.091, val_Loss: 596.725\n",
      "Epoch: 431, train_Loss: 98.667, val_Loss: 595.882\n",
      "Epoch: 432, train_Loss: 98.260, val_Loss: 594.312\n",
      "Epoch: 433, train_Loss: 97.870, val_Loss: 597.287\n",
      "Epoch: 434, train_Loss: 95.763, val_Loss: 607.626\n",
      "Epoch: 435, train_Loss: 120.948, val_Loss: 603.682\n",
      "Epoch: 436, train_Loss: 117.846, val_Loss: 613.895\n",
      "Epoch: 437, train_Loss: 186.124, val_Loss: 609.800\n",
      "Epoch: 438, train_Loss: 129.960, val_Loss: 607.602\n",
      "Epoch: 439, train_Loss: 109.793, val_Loss: 598.032\n",
      "Epoch: 440, train_Loss: 98.116, val_Loss: 605.544\n",
      "Epoch: 441, train_Loss: 92.829, val_Loss: 596.136\n",
      "Epoch: 442, train_Loss: 94.558, val_Loss: 594.276\n",
      "Epoch: 443, train_Loss: 91.743, val_Loss: 602.646\n",
      "Epoch: 444, train_Loss: 90.937, val_Loss: 594.714\n",
      "Epoch: 445, train_Loss: 92.963, val_Loss: 603.827\n",
      "Epoch: 446, train_Loss: 91.265, val_Loss: 608.841\n",
      "Epoch: 447, train_Loss: 96.476, val_Loss: 598.312\n",
      "Epoch: 448, train_Loss: 96.386, val_Loss: 610.021\n",
      "Epoch: 449, train_Loss: 97.137, val_Loss: 607.882\n",
      "Epoch: 450, train_Loss: 92.586, val_Loss: 603.157\n",
      "Epoch: 451, train_Loss: 95.777, val_Loss: 617.673\n",
      "Epoch: 452, train_Loss: 97.452, val_Loss: 604.803\n",
      "Epoch: 453, train_Loss: 105.359, val_Loss: 615.302\n",
      "Epoch: 454, train_Loss: 103.680, val_Loss: 607.366\n",
      "Epoch: 455, train_Loss: 99.744, val_Loss: 607.728\n",
      "Epoch: 456, train_Loss: 96.149, val_Loss: 600.345\n",
      "Epoch: 457, train_Loss: 98.812, val_Loss: 603.968\n",
      "Epoch: 458, train_Loss: 95.543, val_Loss: 609.046\n",
      "Epoch: 459, train_Loss: 89.865, val_Loss: 606.189\n",
      "Epoch: 460, train_Loss: 92.649, val_Loss: 594.035\n",
      "Epoch: 461, train_Loss: 93.306, val_Loss: 599.596\n",
      "Epoch: 462, train_Loss: 91.178, val_Loss: 591.453\n",
      "Epoch: 463, train_Loss: 94.213, val_Loss: 595.714\n",
      "Epoch: 464, train_Loss: 91.131, val_Loss: 589.429\n",
      "Epoch: 465, train_Loss: 88.636, val_Loss: 607.632\n",
      "Epoch: 466, train_Loss: 86.243, val_Loss: 606.646\n",
      "Epoch: 467, train_Loss: 89.897, val_Loss: 601.808\n",
      "Epoch: 468, train_Loss: 105.491, val_Loss: 612.380\n",
      "Epoch: 469, train_Loss: 101.314, val_Loss: 607.018\n",
      "Epoch: 470, train_Loss: 89.493, val_Loss: 605.682\n",
      "Epoch: 471, train_Loss: 86.310, val_Loss: 606.826\n",
      "Epoch: 472, train_Loss: 86.165, val_Loss: 602.211\n",
      "Epoch: 473, train_Loss: 89.222, val_Loss: 601.669\n",
      "Epoch: 474, train_Loss: 94.368, val_Loss: 600.994\n",
      "Epoch: 475, train_Loss: 92.556, val_Loss: 601.821\n",
      "Epoch: 476, train_Loss: 96.341, val_Loss: 605.964\n",
      "Epoch: 477, train_Loss: 104.424, val_Loss: 618.970\n",
      "Epoch: 478, train_Loss: 99.388, val_Loss: 615.093\n",
      "Epoch: 479, train_Loss: 89.167, val_Loss: 599.820\n",
      "Epoch: 480, train_Loss: 86.563, val_Loss: 601.207\n",
      "Epoch: 481, train_Loss: 83.250, val_Loss: 605.043\n",
      "Epoch: 482, train_Loss: 85.296, val_Loss: 639.393\n",
      "Epoch: 483, train_Loss: 94.030, val_Loss: 611.629\n",
      "Epoch: 484, train_Loss: 87.212, val_Loss: 601.422\n",
      "Epoch: 485, train_Loss: 83.591, val_Loss: 604.878\n",
      "Epoch: 486, train_Loss: 84.569, val_Loss: 600.089\n",
      "Epoch: 487, train_Loss: 109.592, val_Loss: 612.056\n",
      "Epoch: 488, train_Loss: 100.801, val_Loss: 606.250\n",
      "Epoch: 489, train_Loss: 89.434, val_Loss: 607.980\n",
      "Epoch: 490, train_Loss: 86.295, val_Loss: 615.553\n",
      "Epoch: 491, train_Loss: 86.256, val_Loss: 607.082\n",
      "Epoch: 492, train_Loss: 89.813, val_Loss: 603.202\n",
      "Epoch: 493, train_Loss: 98.982, val_Loss: 603.678\n",
      "Epoch: 494, train_Loss: 91.579, val_Loss: 613.583\n",
      "Epoch: 495, train_Loss: 87.866, val_Loss: 611.255\n",
      "Epoch: 496, train_Loss: 128.946, val_Loss: 619.494\n",
      "Epoch: 497, train_Loss: 150.096, val_Loss: 605.763\n",
      "Epoch: 498, train_Loss: 166.469, val_Loss: 608.300\n",
      "Epoch: 499, train_Loss: 169.414, val_Loss: 620.466\n",
      "Epoch: 500, train_Loss: 201.711, val_Loss: 620.617\n"
     ]
    }
   ],
   "source": [
    "model = LSTM_Predictor(dataset)\n",
    "model = model.to(device)\n",
    "train_losses, val_losses = train(dataset, train_dataset, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "27a7152e-3438-43f2-9432-f1b189df9404",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predect(dataset, test_dataset, model):\n",
    "    model.eval()\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=5, drop_last=True)\n",
    "\n",
    "    index = np.random.choice(len(test_dataloader))\n",
    "    \n",
    "    for batch, (x, y) in enumerate(test_dataloader):\n",
    "    \n",
    "        smiles, wavelength = x, y\n",
    "        break\n",
    "    state_h, state_c = model.init_state(5)\n",
    "    state_h = state_h.to(device)\n",
    "    state_c = state_c.to(device)\n",
    "    y_pred, (state_h, state_c) = model(smiles.to(device), (state_h, state_c))\n",
    "    y_pred_permute = torch.permute(y_pred, (2, 1, 0))    \n",
    "\n",
    "    print(y_pred_permute)\n",
    "    print(wavelength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "df41f473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[  14.5500,  -81.7151,  -81.7151,  -81.7151,  -81.7151],\n",
      "         [  18.6561, -135.8523, -107.5618, -135.8523, -135.8523],\n",
      "         [   2.6926, -122.1999, -141.5083, -122.1999, -133.0245],\n",
      "         [-128.4654,  -91.1423, -134.7980,  -91.1423, -121.5029],\n",
      "         [ -34.9340,  -51.2219, -126.2469,  -51.2219,  -47.4559],\n",
      "         [ -57.8880,  -61.0764, -118.8487,  -61.0764, -103.4670],\n",
      "         [ -24.2579,  -50.5599, -106.9901,  -50.5599, -149.6742],\n",
      "         [ -15.0138,  -44.6332, -138.5503,  -44.6332, -122.3770],\n",
      "         [ -35.8738,  -64.9682, -105.4377,  -35.4145, -128.3328],\n",
      "         [ -14.4116,  -40.3567,  -89.1473,  -69.2478,  -61.8977],\n",
      "         [  11.9581,  -28.0963,  -89.9188,  -61.2954,  -55.9325],\n",
      "         [  57.7219,  -55.2112,  -73.4436,  -40.6783,  -66.5821],\n",
      "         [ 110.5460,  -50.5090,  -83.9938,  -77.0135,  -66.5376],\n",
      "         [ 205.5531,  -38.0316,  -72.1703, -139.6108,  -93.9077],\n",
      "         [ 343.4565,  -68.7247,  -67.5248,  -83.7919, -105.0512],\n",
      "         [ 408.4885, -100.0361,  -67.2466, -143.0138,  -99.7122],\n",
      "         [ 384.1251, -109.2287,  -64.6734,  -59.0143, -118.9408],\n",
      "         [ 350.6595,  -48.8598,  -26.4863,  -87.4807, -108.8360],\n",
      "         [ 356.0234, -105.8074,  -10.4979,  -53.4069, -109.5405],\n",
      "         [ 336.1806,  -73.3902,  -33.6098,  -57.4963,  -58.3634],\n",
      "         [ 338.2831,  -59.0110,    7.0908, -113.3605,  -86.1338],\n",
      "         [ 342.1367,  -59.4169,   -7.0594, -103.0294,  -51.0098],\n",
      "         [ 342.9311,  -59.3527,   -1.6069, -165.1117,  -57.2292],\n",
      "         [ 353.7685,  -15.8787,   13.6957, -135.0496,  -37.3451],\n",
      "         [ 340.7435,   -0.5828,   19.4524, -124.7250,  -45.3785],\n",
      "         [ 340.1388,    8.9972,   29.1967,  -83.9894,  -56.7111],\n",
      "         [ 346.2038,   36.7119,   16.4528,  -78.8398,  -28.5076],\n",
      "         [ 340.8730,   57.9472,   19.7106,  -63.0968,  -32.4927],\n",
      "         [ 319.3113,  114.7448,   27.9232,  -70.8176,  -10.3498],\n",
      "         [ 306.9055,  230.1146,   55.4615,  -67.6123,   23.5666],\n",
      "         [ 307.6221,  283.5594,  142.0899,  -73.8299,   21.4755],\n",
      "         [ 305.3674,  304.8307,  186.6502, -103.4624,   30.4219],\n",
      "         [ 315.2732,  317.3456,  221.2465,  -56.5525,   48.9207],\n",
      "         [ 317.3139,  325.6559,  253.6134,  -43.6100,   79.4913],\n",
      "         [ 311.6432,  332.1722,  294.3231,  -79.0203,  112.3736],\n",
      "         [ 315.3459,  334.4385,  307.3628,  -97.5740,  146.1815],\n",
      "         [ 321.0696,  330.5002,  332.6752,  -40.8711,  195.3903],\n",
      "         [ 325.2408,  325.5548,  338.6172,  -60.9984,  250.1737],\n",
      "         [ 325.3240,  322.6499,  350.6552,  -41.5053,  324.3450],\n",
      "         [ 325.6144,  309.1252,  352.6769,   -5.3870,  366.2880],\n",
      "         [ 323.3249,  293.6087,  362.0742,   -3.4473,  371.2726],\n",
      "         [ 319.2609,  283.9577,  362.0018,   10.0985,  373.4370],\n",
      "         [ 313.9254,  280.2341,  363.9531,   17.9096,  362.2291],\n",
      "         [ 309.7987,  278.6485,  366.6583,   42.2295,  360.6154],\n",
      "         [ 303.2997,  278.2638,  377.2574,   80.3753,  359.6572],\n",
      "         [ 298.7628,  278.3704,  372.5104,  142.1974,  358.4825],\n",
      "         [ 295.3191,  278.5782,  363.0619,  206.3146,  358.5562],\n",
      "         [ 292.8468,  278.6828,  353.7811,  249.6038,  360.7162],\n",
      "         [ 290.5780,  278.6164,  349.6831,  268.6166,  360.2177],\n",
      "         [ 288.7497,  278.4106,  346.4039,  272.6462,  356.3749],\n",
      "         [ 287.6942,  278.1203,  342.8391,  271.7705,  348.6611],\n",
      "         [ 287.1837,  277.8384,  341.0010,  271.3057,  341.1814],\n",
      "         [ 286.9186,  277.6249,  339.9934,  270.9900,  337.1304],\n",
      "         [ 286.7513,  277.4893,  337.1525,  270.2523,  335.2095],\n",
      "         [ 286.6219,  277.4137,  334.6539,  269.0089,  334.6402],\n",
      "         [ 286.5093,  277.3782,  332.7758,  267.7346,  335.3123],\n",
      "         [ 286.4055,  277.3697,  332.0175,  267.3295,  338.6235],\n",
      "         [ 286.3068,  277.3783,  332.6457,  267.6019,  340.9342],\n",
      "         [ 286.2099,  277.3977,  333.1060,  268.2952,  340.5012],\n",
      "         [ 286.1149,  277.4236,  333.0498,  269.0984,  339.5850],\n",
      "         [ 286.0192,  277.4536,  332.5342,  269.7830,  338.3914],\n",
      "         [ 285.9237,  277.4870,  331.9582,  270.1544,  336.7115],\n",
      "         [ 285.8283,  277.5220,  331.1509,  269.4715,  335.7401],\n",
      "         [ 285.7313,  277.5581,  329.4732,  265.3420,  335.4230],\n",
      "         [ 285.6345,  277.5936,  328.4617,  260.0234,  335.2923],\n",
      "         [ 285.5367,  277.6292,  328.2264,  257.8279,  335.2186],\n",
      "         [ 285.4381,  277.6635,  328.2047,  256.8083,  335.1543],\n",
      "         [ 285.3415,  277.6972,  328.2250,  256.2385,  335.0686],\n",
      "         [ 285.2465,  277.7287,  328.2485,  256.1771,  334.8975],\n",
      "         [ 285.1532,  277.7587,  328.2685,  257.9149,  334.5786],\n",
      "         [ 285.0610,  277.7860,  328.2850,  263.9556,  334.2224],\n",
      "         [ 284.9717,  277.8123,  328.2997,  268.5325,  333.9737],\n",
      "         [ 284.8837,  277.8365,  328.3136,  269.4658,  333.8157],\n",
      "         [ 284.7985,  277.8587,  328.3282,  269.5324,  333.6992],\n",
      "         [ 284.7121,  277.8792,  328.3433,  269.4655,  333.6024],\n",
      "         [ 284.6242,  277.8974,  328.3594,  269.3801,  333.5132],\n",
      "         [ 284.5367,  277.9133,  328.3769,  269.2991,  333.4290],\n",
      "         [ 284.4482,  277.9274,  328.3955,  269.2272,  333.3487],\n",
      "         [ 284.3580,  277.9386,  328.4158,  269.1634,  333.2715]]],\n",
      "       device='cuda:0', grad_fn=<PermuteBackward0>)\n",
      "tensor([320.1200, 275.1200, 337.2000, 257.5100, 387.2400])\n"
     ]
    }
   ],
   "source": [
    "predect(dataset, test_dataset, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cc12867b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12,4))\n",
    "axes[0].plot(train_losses, label=\"train_Loss\")\n",
    "axes[0].plot(val_losses, label=\"val_Loss\")\n",
    "axes[0].grid()\n",
    "axes[0].set_xlabel(\"epoch\")\n",
    "axes[0].legend()\n",
    "\n",
    "\n",
    "axes[1].plot(train_losses, label=\"train_Loss\")\n",
    "axes[1].plot(val_losses, label=\"val_Loss\")\n",
    "axes[1].grid()\n",
    "axes[1].set_yscale('log')\n",
    "axes[1].set_xlabel(\"epoch\")\n",
    "axes[1].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "91fdc21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataset, test_dataset, model):\n",
    "    model.eval()\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=len(test_dataset), drop_last=True)\n",
    "    \n",
    "    criterion = torch.nn.L1Loss()\n",
    "    \n",
    "    total_loss = 0\n",
    "    state_h, state_c = model.init_state(len(test_dataset))\n",
    "    state_h = state_h.to(device)\n",
    "    state_c = state_c.to(device)\n",
    "    \n",
    "    for batch, (x, y) in enumerate(test_dataloader):\n",
    "    \n",
    "        y_pred, (state_h, state_c) = model(x.to(device), (state_h, state_c))\n",
    "        y_pred_permute = torch.permute(y_pred, (2, 1, 0))    \n",
    "        loss = criterion(y_pred_permute[0, dataset.max_length-1], y.to(device))\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        state_h = state_h.detach()\n",
    "        state_c = state_c.detach()\n",
    "    \n",
    "    return total_loss\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ce14c760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_Loss: 25.896\n"
     ]
    }
   ],
   "source": [
    "print(\"test_Loss: {:.3f}\".format(test(dataset, test_dataset, model)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "91fdc21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataset, test_dataset, model):\n",
    "    model.eval()\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=len(test_dataset), drop_last=True)\n",
    "    \n",
    "    criterion = torch.nn.MSELoss()\n",
    "    \n",
    "    total_loss = 0\n",
    "    state_h, state_c = model.init_state(len(test_dataset))\n",
    "    state_h = state_h.to(device)\n",
    "    state_c = state_c.to(device)\n",
    "    \n",
    "    for batch, (x, y) in enumerate(test_dataloader):\n",
    "    \n",
    "        y_pred, (state_h, state_c) = model(x.to(device), (state_h, state_c))\n",
    "        y_pred_permute = torch.permute(y_pred, (2, 1, 0))    \n",
    "        loss = criterion(y_pred_permute[0, dataset.max_length-1], y.to(device))\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        state_h = state_h.detach()\n",
    "        state_c = state_c.detach()\n",
    "    \n",
    "    return total_loss\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ce14c760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_Loss: 1602.814\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m現在のセルまたは前のセルでコードを実行中に、カーネルがクラッシュしました。エラーの原因を特定するには、セル内のコードを確認してください。詳細については、<a href='https://aka.ms/vscodeJupyterKernelCrash'>こちら</a> をクリックしてください。さらなる詳細については、Jupyter [log] (command:jupyter.viewOutput) を参照してください。"
     ]
    }
   ],
   "source": [
    "print(\"test_Loss: {:.3f}\".format(test(dataset, test_dataset, model)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
